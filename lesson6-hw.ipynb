{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f648ba3d",
      "metadata": {
        "papermill": {
          "duration": 0.013111,
          "end_time": "2022-07-15T01:11:26.703965",
          "exception": false,
          "start_time": "2022-07-15T01:11:26.690854",
          "status": "completed"
        },
        "tags": [],
        "id": "f648ba3d"
      },
      "source": [
        "## Домашнее задание 6.\n",
        "\n",
        "1. Попробуйте обучить нейронную сеть с применением одномерных сверток для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
        "\n",
        "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe7455a7",
      "metadata": {
        "papermill": {
          "duration": 0.012979,
          "end_time": "2022-07-15T01:11:26.733417",
          "exception": false,
          "start_time": "2022-07-15T01:11:26.720438",
          "status": "completed"
        },
        "tags": [],
        "id": "fe7455a7"
      },
      "source": [
        "## Решение"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5f9f55",
      "metadata": {
        "papermill": {
          "duration": 0.012168,
          "end_time": "2022-07-15T01:11:26.761571",
          "exception": false,
          "start_time": "2022-07-15T01:11:26.749403",
          "status": "completed"
        },
        "tags": [],
        "id": "dc5f9f55"
      },
      "source": [
        "Сначала импортируем все библиотеки, которые будут необходимы при дальнейшем решении задачи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23ea3c7",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:26.785349Z",
          "iopub.status.busy": "2022-07-15T01:11:26.784740Z",
          "iopub.status.idle": "2022-07-15T01:11:31.032533Z",
          "shell.execute_reply": "2022-07-15T01:11:31.031591Z"
        },
        "papermill": {
          "duration": 4.262782,
          "end_time": "2022-07-15T01:11:31.035176",
          "exception": false,
          "start_time": "2022-07-15T01:11:26.772394",
          "status": "completed"
        },
        "tags": [],
        "id": "f23ea3c7",
        "outputId": "ab8335e7-6623-4fb1-97de-3e7fe2526c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from google.colab import drive\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from string import punctuation\n",
        "from textblob import TextBlob, Word\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from itertools import islice\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/drive')"
      ],
      "metadata": {
        "id": "Be6ksg726mDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2c83af-4191-4896-a375-5094d07d33ea"
      },
      "id": "Be6ksg726mDq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597aa927",
      "metadata": {
        "papermill": {
          "duration": 0.010313,
          "end_time": "2022-07-15T01:11:31.056941",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.046628",
          "status": "completed"
        },
        "tags": [],
        "id": "597aa927"
      },
      "source": [
        "Проведем стандартную проверку на наличие видеокарты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ce0e44",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.079522Z",
          "iopub.status.busy": "2022-07-15T01:11:31.079089Z",
          "iopub.status.idle": "2022-07-15T01:11:31.143667Z",
          "shell.execute_reply": "2022-07-15T01:11:31.142754Z"
        },
        "papermill": {
          "duration": 0.077967,
          "end_time": "2022-07-15T01:11:31.145641",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.067674",
          "status": "completed"
        },
        "tags": [],
        "id": "e8ce0e44",
        "outputId": "1e7fddba-e2a6-475e-bfd7-ae5f43f539dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "790c191f",
      "metadata": {
        "papermill": {
          "duration": 0.01049,
          "end_time": "2022-07-15T01:11:31.166685",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.156195",
          "status": "completed"
        },
        "tags": [],
        "id": "790c191f"
      },
      "source": [
        "Зададим ряд гиперпараметров, которые будут использоваться в дальнейшем процессе обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2945320f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.189262Z",
          "iopub.status.busy": "2022-07-15T01:11:31.188925Z",
          "iopub.status.idle": "2022-07-15T01:11:31.193452Z",
          "shell.execute_reply": "2022-07-15T01:11:31.192435Z"
        },
        "papermill": {
          "duration": 0.018695,
          "end_time": "2022-07-15T01:11:31.195754",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.177059",
          "status": "completed"
        },
        "tags": [],
        "id": "2945320f"
      },
      "outputs": [],
      "source": [
        "max_words = 1500\n",
        "max_len = 15\n",
        "num_classes = 1\n",
        "\n",
        "# Training\n",
        "epochs = 7\n",
        "batch_size = 512\n",
        "embedding_dim = 256\n",
        "out_channel = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eecc210",
      "metadata": {
        "papermill": {
          "duration": 0.010442,
          "end_time": "2022-07-15T01:11:31.216684",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.206242",
          "status": "completed"
        },
        "tags": [],
        "id": "0eecc210"
      },
      "source": [
        "Считываем тренировочный датасет, на основе которого будем обучать нейросеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb88996",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.240305Z",
          "iopub.status.busy": "2022-07-15T01:11:31.239705Z",
          "iopub.status.idle": "2022-07-15T01:11:31.379389Z",
          "shell.execute_reply": "2022-07-15T01:11:31.378526Z"
        },
        "papermill": {
          "duration": 0.15449,
          "end_time": "2022-07-15T01:11:31.381552",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.227062",
          "status": "completed"
        },
        "tags": [],
        "id": "9fb88996",
        "outputId": "92a6d453-25d6-4428-fc2c-1453db4fc92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ac16db7-accd-450b-aafe-4c60542a96ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ac16db7-accd-450b-aafe-4c60542a96ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ac16db7-accd-450b-aafe-4c60542a96ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ac16db7-accd-450b-aafe-4c60542a96ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "DATA_ROOT = '/drive/MyDrive/!!GeekBrains/31 Pythoch для разработки ИНС/!Пономарева/6 Нейросети в обработке текста'\n",
        "\n",
        "df_train = pd.read_csv(DATA_ROOT + \"/train.csv\")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63653987",
      "metadata": {
        "papermill": {
          "duration": 0.010572,
          "end_time": "2022-07-15T01:11:31.404126",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.393554",
          "status": "completed"
        },
        "tags": [],
        "id": "63653987"
      },
      "source": [
        "В данном случае мы имеем дело с несбалансированным датасетом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc36c7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.427053Z",
          "iopub.status.busy": "2022-07-15T01:11:31.426711Z",
          "iopub.status.idle": "2022-07-15T01:11:31.439342Z",
          "shell.execute_reply": "2022-07-15T01:11:31.438358Z"
        },
        "papermill": {
          "duration": 0.026209,
          "end_time": "2022-07-15T01:11:31.441240",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.415031",
          "status": "completed"
        },
        "tags": [],
        "id": "cbc36c7c",
        "outputId": "e5237df6-5a6d-48bf-b9de-4e67a78ccfc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ba8c5f0",
      "metadata": {
        "papermill": {
          "duration": 0.010559,
          "end_time": "2022-07-15T01:11:31.462380",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.451821",
          "status": "completed"
        },
        "tags": [],
        "id": "9ba8c5f0"
      },
      "source": [
        "Сразу разделим данные на обучающий и валидационный наборы, добавим стратификацию, чтобы сохранить пропорции классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e384d12",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.485938Z",
          "iopub.status.busy": "2022-07-15T01:11:31.485023Z",
          "iopub.status.idle": "2022-07-15T01:11:31.506929Z",
          "shell.execute_reply": "2022-07-15T01:11:31.506065Z"
        },
        "papermill": {
          "duration": 0.036121,
          "end_time": "2022-07-15T01:11:31.509089",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.472968",
          "status": "completed"
        },
        "tags": [],
        "id": "6e384d12"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df_train['tweet'], \n",
        "                                                  df_train['label'], \n",
        "                                                  test_size=0.3, \n",
        "                                                  random_state=42, \n",
        "                                                  stratify=df_train['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "284880ba",
      "metadata": {
        "papermill": {
          "duration": 0.011082,
          "end_time": "2022-07-15T01:11:31.531613",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.520531",
          "status": "completed"
        },
        "tags": [],
        "id": "284880ba"
      },
      "source": [
        "Теперь перейдем к предобработке твитов. Для начала сформируем множество стоп слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ff3051",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.557739Z",
          "iopub.status.busy": "2022-07-15T01:11:31.555861Z",
          "iopub.status.idle": "2022-07-15T01:11:31.571613Z",
          "shell.execute_reply": "2022-07-15T01:11:31.570583Z"
        },
        "papermill": {
          "duration": 0.030415,
          "end_time": "2022-07-15T01:11:31.573536",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.543121",
          "status": "completed"
        },
        "tags": [],
        "id": "89ff3051",
        "outputId": "67be7c87-2a1e-4219-b9ef-037c8d6c66cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'amp',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'user',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sw = set(stopwords.words(\"english\"))\n",
        "# Добавим к стандартному множеству еще одно слово, которое не несет смысловой нагрузки,\n",
        "# но часто встречается как текстовое представление символа - &amp; \n",
        "sw.add('amp')\n",
        "# Добавим user, так как в данном датасете это является обезличенным \n",
        "# упоминанием пользователя в твите\n",
        "sw.add('user')\n",
        "sw"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f536aecb",
      "metadata": {
        "papermill": {
          "duration": 0.010885,
          "end_time": "2022-07-15T01:11:31.596306",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.585421",
          "status": "completed"
        },
        "tags": [],
        "id": "f536aecb"
      },
      "source": [
        "Сформируем дополнительно список знаков пунктуации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "153ba8aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.620470Z",
          "iopub.status.busy": "2022-07-15T01:11:31.618888Z",
          "iopub.status.idle": "2022-07-15T01:11:31.626712Z",
          "shell.execute_reply": "2022-07-15T01:11:31.625796Z"
        },
        "papermill": {
          "duration": 0.021521,
          "end_time": "2022-07-15T01:11:31.628621",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.607100",
          "status": "completed"
        },
        "tags": [],
        "id": "153ba8aa",
        "outputId": "4d89dcf5-f45b-47cf-a07b-6ea95347f464",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "puncts = set(punctuation)\n",
        "puncts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9efc582e",
      "metadata": {
        "papermill": {
          "duration": 0.010938,
          "end_time": "2022-07-15T01:11:31.650562",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.639624",
          "status": "completed"
        },
        "tags": [],
        "id": "9efc582e"
      },
      "source": [
        "Напишем функцию по аналогии с представленной на лекции, которая будет производить предобработку подаваемого текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf9a200",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.674710Z",
          "iopub.status.busy": "2022-07-15T01:11:31.673888Z",
          "iopub.status.idle": "2022-07-15T01:11:31.680978Z",
          "shell.execute_reply": "2022-07-15T01:11:31.679868Z"
        },
        "papermill": {
          "duration": 0.020995,
          "end_time": "2022-07-15T01:11:31.683009",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.662014",
          "status": "completed"
        },
        "tags": [],
        "id": "6bf9a200"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    # уберем нечитаемые символы типа  ð\\x9f¤\\x97\n",
        "    txt = \"\".join([c for c in txt if ord(c) < 128])\n",
        "    txt = \"\".join(c for c in txt if c not in puncts)\n",
        "    txt = txt.lower()\n",
        "    # преобразуем отрицания\n",
        "    txt = re.sub(\"not\\s\", \"not\", txt)\n",
        "    txt = re.sub(\"no\\s\", \"no\", txt)\n",
        "    # будем приводить формы к глаголам\n",
        "    txt = [Word(word).lemmatize('v') for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49bb8334",
      "metadata": {
        "papermill": {
          "duration": 0.010976,
          "end_time": "2022-07-15T01:11:31.705443",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.694467",
          "status": "completed"
        },
        "tags": [],
        "id": "49bb8334"
      },
      "source": [
        "Посмотрим на примерах на результат работы предобработки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "327a771e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.730445Z",
          "iopub.status.busy": "2022-07-15T01:11:31.730089Z",
          "iopub.status.idle": "2022-07-15T01:11:31.736613Z",
          "shell.execute_reply": "2022-07-15T01:11:31.735666Z"
        },
        "papermill": {
          "duration": 0.021115,
          "end_time": "2022-07-15T01:11:31.738521",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.717406",
          "status": "completed"
        },
        "tags": [],
        "id": "327a771e",
        "outputId": "b5c29ac1-df96-4c8f-87b7-8e4f9fabeb74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy bihday to my brother man. needed this mixtape like we need boos. have a good one sach   @user ',\n",
              "       '  lang to sta the week right :)  #happiness #smile ',\n",
              "       'note it meditate on it work on it ,but most impoantly trust god for it #icantwaitfohedayhisplansformylifeunfold #grateful  ',\n",
              "       '@user listening to you this wet mon, ahead of #leedsmillenium gig next month   ð\\x9f\\x98\\x86ð\\x9f\\x91\\x8dð\\x9f\\x98\\x8d #music #ace ',\n",
              "       '@user @user agreed.. the same is true for  and .. they are overused terms, and as a result, are fast becominâ\\x80¦',\n",
              "       'very exciting! #dubllife #recycle ',\n",
              "       '#bad times #drink   #nobev ',\n",
              "       '#ootd #converse #denim #tshi  #shopping  #like4like #l4l #f4f #instagood  ',\n",
              "       '  #fathersday to the man of my dreams! you sacrificed bachelorhood for a ready-made familyâ\\x80¦ ',\n",
              "       '  #pougalday #pay #saturday #fresh #new #haircut &amp; new #red #car in #style #chillingâ\\x80¦ '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train.iloc[:10].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caa7ee71",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:31.761943Z",
          "iopub.status.busy": "2022-07-15T01:11:31.761642Z",
          "iopub.status.idle": "2022-07-15T01:11:33.521948Z",
          "shell.execute_reply": "2022-07-15T01:11:33.521075Z"
        },
        "papermill": {
          "duration": 1.774722,
          "end_time": "2022-07-15T01:11:33.524308",
          "exception": false,
          "start_time": "2022-07-15T01:11:31.749586",
          "status": "completed"
        },
        "tags": [],
        "id": "caa7ee71",
        "outputId": "45dab1ca-f5e4-4f4c-8eb6-faf66104bf83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy bihday brother man need mixtape like need boo good one sach',\n",
              "       'lang sta week right happiness smile',\n",
              "       'note meditate work impoantly trust god icantwaitfohedayhisplansformylifeunfold grateful',\n",
              "       'listen wet mon ahead leedsmillenium gig next month music ace',\n",
              "       'agree true overuse term result fast becomin',\n",
              "       'excite dubllife recycle', 'bad time drink nobev',\n",
              "       'ootd converse denim tshi shop like4like l4l f4f instagood',\n",
              "       'fathersday man dream sacrifice bachelorhood readymade family',\n",
              "       'pougalday pay saturday fresh new haircut new red car style chill'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X_train.iloc[:10].apply(preprocess_text).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cef5d556",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T23:32:58.963688Z",
          "iopub.status.busy": "2022-07-14T23:32:58.963076Z",
          "iopub.status.idle": "2022-07-14T23:32:58.971592Z",
          "shell.execute_reply": "2022-07-14T23:32:58.970080Z",
          "shell.execute_reply.started": "2022-07-14T23:32:58.963653Z"
        },
        "papermill": {
          "duration": 0.01152,
          "end_time": "2022-07-15T01:11:33.547492",
          "exception": false,
          "start_time": "2022-07-15T01:11:33.535972",
          "status": "completed"
        },
        "tags": [],
        "id": "cef5d556"
      },
      "source": [
        "Теперь преобразуем тексты всех твитов с помощью данной функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03e85a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:33.570511Z",
          "iopub.status.busy": "2022-07-15T01:11:33.570216Z",
          "iopub.status.idle": "2022-07-15T01:11:36.277568Z",
          "shell.execute_reply": "2022-07-15T01:11:36.276515Z"
        },
        "papermill": {
          "duration": 2.721754,
          "end_time": "2022-07-15T01:11:36.280147",
          "exception": false,
          "start_time": "2022-07-15T01:11:33.558393",
          "status": "completed"
        },
        "tags": [],
        "id": "f03e85a8"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(preprocess_text).values\n",
        "X_val = X_val.apply(preprocess_text).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e060bad",
      "metadata": {
        "papermill": {
          "duration": 0.011672,
          "end_time": "2022-07-15T01:11:36.303446",
          "exception": false,
          "start_time": "2022-07-15T01:11:36.291774",
          "status": "completed"
        },
        "tags": [],
        "id": "7e060bad"
      },
      "source": [
        "Перейдем к реализации процесса токенизации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5b89eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:36.329493Z",
          "iopub.status.busy": "2022-07-15T01:11:36.327573Z",
          "iopub.status.idle": "2022-07-15T01:11:36.335694Z",
          "shell.execute_reply": "2022-07-15T01:11:36.334767Z"
        },
        "papermill": {
          "duration": 0.023284,
          "end_time": "2022-07-15T01:11:36.337831",
          "exception": false,
          "start_time": "2022-07-15T01:11:36.314547",
          "status": "completed"
        },
        "tags": [],
        "id": "3c5b89eb"
      },
      "outputs": [],
      "source": [
        "train_corpus = \" \".join(X_train)\n",
        "train_corpus = train_corpus.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb8dbc1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:36.361252Z",
          "iopub.status.busy": "2022-07-15T01:11:36.360974Z",
          "iopub.status.idle": "2022-07-15T01:11:37.873762Z",
          "shell.execute_reply": "2022-07-15T01:11:37.872818Z"
        },
        "papermill": {
          "duration": 1.527335,
          "end_time": "2022-07-15T01:11:37.876119",
          "exception": false,
          "start_time": "2022-07-15T01:11:36.348784",
          "status": "completed"
        },
        "tags": [],
        "id": "2eb8dbc1",
        "outputId": "10956da0-e4d6-45e5-f835-d74d669b7968",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['happy', 'bihday', 'brother', 'man', 'need']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07308de",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:37.900743Z",
          "iopub.status.busy": "2022-07-15T01:11:37.900064Z",
          "iopub.status.idle": "2022-07-15T01:11:38.054540Z",
          "shell.execute_reply": "2022-07-15T01:11:38.053591Z"
        },
        "papermill": {
          "duration": 0.169166,
          "end_time": "2022-07-15T01:11:38.056938",
          "exception": false,
          "start_time": "2022-07-15T01:11:37.887772",
          "status": "completed"
        },
        "tags": [],
        "id": "b07308de",
        "outputId": "c0e5aaf7-9bda-48a1-8d3b-8cd7e2bebb48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love', 'day', 'get', 'happy', 'go', 'time', 'make', 'im', 'u', 'life']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
        "\n",
        "# Посмотрим на топ 10 слов\n",
        "tokens_filtered_top[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b430c26c",
      "metadata": {
        "papermill": {
          "duration": 0.011867,
          "end_time": "2022-07-15T01:11:38.080489",
          "exception": false,
          "start_time": "2022-07-15T01:11:38.068622",
          "status": "completed"
        },
        "tags": [],
        "id": "b430c26c"
      },
      "source": [
        "Сформируем словарь, в котором будут храниться наиболее часто встречающиеся слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c58d93",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:38.104615Z",
          "iopub.status.busy": "2022-07-15T01:11:38.104294Z",
          "iopub.status.idle": "2022-07-15T01:11:38.113182Z",
          "shell.execute_reply": "2022-07-15T01:11:38.112289Z"
        },
        "papermill": {
          "duration": 0.023099,
          "end_time": "2022-07-15T01:11:38.115033",
          "exception": false,
          "start_time": "2022-07-15T01:11:38.091934",
          "status": "completed"
        },
        "tags": [],
        "id": "22c58d93",
        "outputId": "bc01551a-f6d7-44d4-bf57-a90cc2834d17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 1),\n",
              " ('day', 2),\n",
              " ('get', 3),\n",
              " ('happy', 4),\n",
              " ('go', 5),\n",
              " ('time', 6),\n",
              " ('make', 7),\n",
              " ('im', 8),\n",
              " ('u', 9),\n",
              " ('life', 10),\n",
              " ('like', 11),\n",
              " ('today', 12),\n",
              " ('new', 13),\n",
              " ('father', 14),\n",
              " ('see', 15),\n",
              " ('positive', 16),\n",
              " ('smile', 17),\n",
              " ('thankful', 18),\n",
              " ('people', 19),\n",
              " ('bihday', 20)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "def take(n, iterable):\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
        "take(20, vocabulary.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca8afbd6",
      "metadata": {
        "papermill": {
          "duration": 0.01147,
          "end_time": "2022-07-15T01:11:38.138235",
          "exception": false,
          "start_time": "2022-07-15T01:11:38.126765",
          "status": "completed"
        },
        "tags": [],
        "id": "ca8afbd6"
      },
      "source": [
        "Запишем функцию преобразования текста в токены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123a94cd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:38.162231Z",
          "iopub.status.busy": "2022-07-15T01:11:38.161904Z",
          "iopub.status.idle": "2022-07-15T01:11:38.168296Z",
          "shell.execute_reply": "2022-07-15T01:11:38.167282Z"
        },
        "papermill": {
          "duration": 0.020743,
          "end_time": "2022-07-15T01:11:38.170263",
          "exception": false,
          "start_time": "2022-07-15T01:11:38.149520",
          "status": "completed"
        },
        "tags": [],
        "id": "123a94cd"
      },
      "outputs": [],
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "    return result[-maxlen:] + padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8165a6df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:38.196012Z",
          "iopub.status.busy": "2022-07-15T01:11:38.195027Z",
          "iopub.status.idle": "2022-07-15T01:11:43.238836Z",
          "shell.execute_reply": "2022-07-15T01:11:43.237389Z"
        },
        "papermill": {
          "duration": 5.059628,
          "end_time": "2022-07-15T01:11:43.241693",
          "exception": false,
          "start_time": "2022-07-15T01:11:38.182065",
          "status": "completed"
        },
        "tags": [],
        "id": "8165a6df",
        "outputId": "82e1c69b-411b-4c15-fbea-5fbf442ca505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.4 s, sys: 10.2 ms, total: 3.41 s\n",
            "Wall time: 3.44 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train])\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in X_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13601f2f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.268960Z",
          "iopub.status.busy": "2022-07-15T01:11:43.268129Z",
          "iopub.status.idle": "2022-07-15T01:11:43.274864Z",
          "shell.execute_reply": "2022-07-15T01:11:43.273847Z"
        },
        "papermill": {
          "duration": 0.022659,
          "end_time": "2022-07-15T01:11:43.276821",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.254162",
          "status": "completed"
        },
        "tags": [],
        "id": "13601f2f",
        "outputId": "1287c1fd-b7a0-4f29-a54b-28b17f304bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([165,  69,  76,  77,  17,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x_train[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d95b79",
      "metadata": {
        "papermill": {
          "duration": 0.011701,
          "end_time": "2022-07-15T01:11:43.299978",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.288277",
          "status": "completed"
        },
        "tags": [],
        "id": "a3d95b79"
      },
      "source": [
        "Соберем сеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebf18fc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.325151Z",
          "iopub.status.busy": "2022-07-15T01:11:43.324315Z",
          "iopub.status.idle": "2022-07-15T01:11:43.335370Z",
          "shell.execute_reply": "2022-07-15T01:11:43.334541Z"
        },
        "papermill": {
          "duration": 0.025604,
          "end_time": "2022-07-15T01:11:43.337285",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.311681",
          "status": "completed"
        },
        "tags": [],
        "id": "bebf18fc"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size=2000, embedding_dim=128, out_channel=128, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.dp = nn.Dropout(0.25)\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv_1 = nn.Conv1d(embedding_dim, out_channel, kernel_size=2)\n",
        "        self.conv_2 = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear_1 = nn.Linear(out_channel, out_channel // 2)\n",
        "        self.linear_2 = nn.Linear(out_channel // 2, num_classes)\n",
        "#         self.linear_1 = nn.Linear(out_channel, num_classes)\n",
        "        \n",
        "    def forward(self, x):        \n",
        "        output = self.embedding(x) # B, L, E\n",
        "        #                       B  E  L         \n",
        "        output = output.permute(0, 2, 1)\n",
        "        output = self.conv_1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.pool(output)\n",
        "\n",
        "        output = self.conv_2(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.pool(output)\n",
        "        output = torch.max(output, axis=2).values\n",
        "        output = self.linear_1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.dp(output)\n",
        "        output = self.linear_2(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7288c7f",
      "metadata": {
        "papermill": {
          "duration": 0.011205,
          "end_time": "2022-07-15T01:11:43.359884",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.348679",
          "status": "completed"
        },
        "tags": [],
        "id": "c7288c7f"
      },
      "source": [
        "Создадим класс датасета и определим даталоадеры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01677d5c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.385387Z",
          "iopub.status.busy": "2022-07-15T01:11:43.384532Z",
          "iopub.status.idle": "2022-07-15T01:11:43.391348Z",
          "shell.execute_reply": "2022-07-15T01:11:43.390376Z"
        },
        "papermill": {
          "duration": 0.021269,
          "end_time": "2022-07-15T01:11:43.393294",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.372025",
          "status": "completed"
        },
        "tags": [],
        "id": "01677d5c"
      },
      "outputs": [],
      "source": [
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7592365",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.418732Z",
          "iopub.status.busy": "2022-07-15T01:11:43.417963Z",
          "iopub.status.idle": "2022-07-15T01:11:43.424111Z",
          "shell.execute_reply": "2022-07-15T01:11:43.423167Z"
        },
        "papermill": {
          "duration": 0.021116,
          "end_time": "2022-07-15T01:11:43.425986",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.404870",
          "status": "completed"
        },
        "tags": [],
        "id": "b7592365"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataWrapper(x_train, y_train.values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(x_val, y_val.values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d5d5686",
      "metadata": {
        "papermill": {
          "duration": 0.011334,
          "end_time": "2022-07-15T01:11:43.448826",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.437492",
          "status": "completed"
        },
        "tags": [],
        "id": "3d5d5686"
      },
      "source": [
        "Обучаем построенную сеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80a64f2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.474096Z",
          "iopub.status.busy": "2022-07-15T01:11:43.473295Z",
          "iopub.status.idle": "2022-07-15T01:11:43.489735Z",
          "shell.execute_reply": "2022-07-15T01:11:43.488824Z"
        },
        "papermill": {
          "duration": 0.031379,
          "end_time": "2022-07-15T01:11:43.491837",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.460458",
          "status": "completed"
        },
        "tags": [],
        "id": "d80a64f2"
      },
      "outputs": [],
      "source": [
        "model = Net(vocab_size=max_words, embedding_dim=embedding_dim, out_channel=out_channel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1adb486",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.517163Z",
          "iopub.status.busy": "2022-07-15T01:11:43.516385Z",
          "iopub.status.idle": "2022-07-15T01:11:43.521758Z",
          "shell.execute_reply": "2022-07-15T01:11:43.520865Z"
        },
        "papermill": {
          "duration": 0.02023,
          "end_time": "2022-07-15T01:11:43.524233",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.504003",
          "status": "completed"
        },
        "tags": [],
        "id": "d1adb486",
        "outputId": "869319c5-3393-4ea6-b7a7-466557bdc451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (dp): Dropout(p=0.25, inplace=False)\n",
            "  (embedding): Embedding(1500, 256)\n",
            "  (conv_1): Conv1d(256, 256, kernel_size=(2,), stride=(1,))\n",
            "  (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
            "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU()\n",
            "  (linear_1): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (linear_2): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "Parameters: 745217\n"
          ]
        }
      ],
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2384d5e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.549647Z",
          "iopub.status.busy": "2022-07-15T01:11:43.548907Z",
          "iopub.status.idle": "2022-07-15T01:11:43.554009Z",
          "shell.execute_reply": "2022-07-15T01:11:43.553181Z"
        },
        "papermill": {
          "duration": 0.019841,
          "end_time": "2022-07-15T01:11:43.555913",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.536072",
          "status": "completed"
        },
        "tags": [],
        "id": "e2384d5e"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b9edbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:11:43.581455Z",
          "iopub.status.busy": "2022-07-15T01:11:43.580844Z",
          "iopub.status.idle": "2022-07-15T01:12:04.493638Z",
          "shell.execute_reply": "2022-07-15T01:12:04.491872Z"
        },
        "papermill": {
          "duration": 20.929145,
          "end_time": "2022-07-15T01:12:04.496519",
          "exception": false,
          "start_time": "2022-07-15T01:11:43.567374",
          "status": "completed"
        },
        "tags": [],
        "id": "50b9edbd",
        "outputId": "9f547001-76b6-4f8e-b940-7ea95e643692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/7]. Step [44/44]. Loss: 0.165. Acc: 0.916. Test loss: 0.084. Test acc: 0.930\n",
            "Epoch [2/7]. Step [44/44]. Loss: 0.205. Acc: 0.930. Test loss: 0.051. Test acc: 0.930\n",
            "Epoch [3/7]. Step [44/44]. Loss: 0.116. Acc: 0.939. Test loss: 0.133. Test acc: 0.944\n",
            "Epoch [4/7]. Step [44/44]. Loss: 0.089. Acc: 0.961. Test loss: 0.889. Test acc: 0.950\n",
            "Epoch [5/7]. Step [44/44]. Loss: 0.103. Acc: 0.974. Test loss: 0.004. Test acc: 0.945\n",
            "Epoch [6/7]. Step [44/44]. Loss: 0.058. Acc: 0.983. Test loss: 0.159. Test acc: 0.942\n",
            "Epoch [7/7]. Step [44/44]. Loss: 0.041. Acc: 0.989. Test loss: 0.002. Test acc: 0.941\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "        \n",
        "    # выводим статистику о процессе обучения\n",
        "    model.eval()\n",
        "    \n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "            f'Loss: {loss:.3f}. ' \\\n",
        "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "        # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = model(data[0].to(device))\n",
        "        \n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "    \n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
        "    \n",
        "    model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29d4155",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:12:04.525042Z",
          "iopub.status.busy": "2022-07-15T01:12:04.524337Z",
          "iopub.status.idle": "2022-07-15T01:12:04.537573Z",
          "shell.execute_reply": "2022-07-15T01:12:04.536711Z"
        },
        "papermill": {
          "duration": 0.029391,
          "end_time": "2022-07-15T01:12:04.539667",
          "exception": false,
          "start_time": "2022-07-15T01:12:04.510276",
          "status": "completed"
        },
        "tags": [],
        "id": "c29d4155"
      },
      "outputs": [],
      "source": [
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "newdata, newtargets = oversample.fit_resample(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd40ab0e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:12:04.566601Z",
          "iopub.status.busy": "2022-07-15T01:12:04.566310Z",
          "iopub.status.idle": "2022-07-15T01:12:04.571096Z",
          "shell.execute_reply": "2022-07-15T01:12:04.570082Z"
        },
        "papermill": {
          "duration": 0.020998,
          "end_time": "2022-07-15T01:12:04.573354",
          "exception": false,
          "start_time": "2022-07-15T01:12:04.552356",
          "status": "completed"
        },
        "tags": [],
        "id": "fd40ab0e"
      },
      "outputs": [],
      "source": [
        "trainnew_dataset = DataWrapper(newdata, newtargets.values)\n",
        "trainnew_loader = DataLoader(trainnew_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ba10c3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:12:04.599231Z",
          "iopub.status.busy": "2022-07-15T01:12:04.598978Z",
          "iopub.status.idle": "2022-07-15T01:12:04.610225Z",
          "shell.execute_reply": "2022-07-15T01:12:04.609379Z"
        },
        "papermill": {
          "duration": 0.026707,
          "end_time": "2022-07-15T01:12:04.612279",
          "exception": false,
          "start_time": "2022-07-15T01:12:04.585572",
          "status": "completed"
        },
        "tags": [],
        "id": "62ba10c3"
      },
      "outputs": [],
      "source": [
        "model = Net(vocab_size=max_words, embedding_dim=embedding_dim, out_channel=out_channel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8d3089",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:12:04.638751Z",
          "iopub.status.busy": "2022-07-15T01:12:04.638478Z",
          "iopub.status.idle": "2022-07-15T01:12:04.643271Z",
          "shell.execute_reply": "2022-07-15T01:12:04.642391Z"
        },
        "papermill": {
          "duration": 0.020315,
          "end_time": "2022-07-15T01:12:04.645155",
          "exception": false,
          "start_time": "2022-07-15T01:12:04.624840",
          "status": "completed"
        },
        "tags": [],
        "id": "9c8d3089"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0efd13c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T01:12:04.671517Z",
          "iopub.status.busy": "2022-07-15T01:12:04.671247Z",
          "iopub.status.idle": "2022-07-15T01:12:18.500597Z",
          "shell.execute_reply": "2022-07-15T01:12:18.499320Z"
        },
        "papermill": {
          "duration": 13.845901,
          "end_time": "2022-07-15T01:12:18.503505",
          "exception": false,
          "start_time": "2022-07-15T01:12:04.657604",
          "status": "completed"
        },
        "tags": [],
        "id": "0efd13c1",
        "outputId": "d16800d5-a7bc-4607-e8bb-f72eddc43181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/7]. Step [82/82]. Loss: 0.141. Acc: 0.851. Test loss: 0.275. Test acc: 0.883\n",
            "Epoch [2/7]. Step [82/82]. Loss: 0.100. Acc: 0.975. Test loss: 0.014. Test acc: 0.935\n",
            "Epoch [3/7]. Step [82/82]. Loss: 0.034. Acc: 0.985. Test loss: 0.000. Test acc: 0.933\n",
            "Epoch [4/7]. Step [82/82]. Loss: 0.021. Acc: 0.988. Test loss: 0.000. Test acc: 0.935\n",
            "Epoch [5/7]. Step [82/82]. Loss: 0.032. Acc: 0.988. Test loss: 0.000. Test acc: 0.936\n",
            "Epoch [6/7]. Step [82/82]. Loss: 0.020. Acc: 0.989. Test loss: 0.002. Test acc: 0.929\n",
            "Epoch [7/7]. Step [82/82]. Loss: 0.030. Acc: 0.984. Test loss: 2.215. Test acc: 0.922\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(trainnew_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "        \n",
        "    # выводим статистику о процессе обучения\n",
        "    model.eval()\n",
        "    \n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "            f'Step [{i + 1}/{len(trainnew_loader)}]. ' \\\n",
        "            f'Loss: {loss:.3f}. ' \\\n",
        "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "        # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = model(data[0].to(device))\n",
        "        \n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "    \n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}. Test acc: {test_running_right / test_running_total:.3f}')\n",
        "    \n",
        "    model.train()\n",
        "        \n",
        "print('Training is finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8421ebf8",
      "metadata": {
        "papermill": {
          "duration": 0.013903,
          "end_time": "2022-07-15T01:12:18.532330",
          "exception": false,
          "start_time": "2022-07-15T01:12:18.518427",
          "status": "completed"
        },
        "tags": [],
        "id": "8421ebf8"
      },
      "source": [
        "Оверсэмплинг не позволил добиться улучшения качества модели."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6620044e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-15T00:57:24.765202Z",
          "iopub.status.busy": "2022-07-15T00:57:24.764496Z",
          "iopub.status.idle": "2022-07-15T00:57:24.774920Z",
          "shell.execute_reply": "2022-07-15T00:57:24.773088Z",
          "shell.execute_reply.started": "2022-07-15T00:57:24.765151Z"
        },
        "papermill": {
          "duration": 0.01304,
          "end_time": "2022-07-15T01:12:18.558887",
          "exception": false,
          "start_time": "2022-07-15T01:12:18.545847",
          "status": "completed"
        },
        "tags": [],
        "id": "6620044e"
      },
      "source": [
        "В процессе экспериментов попробовал:\n",
        "*  изменять параметры лемматизации и в целом процесс предобработки;\n",
        "*  изменять гиперпараметры модели;\n",
        "*  изменять структуру сети;\n",
        "*  изменять оптимизаторы и их гиперпараметры.\n",
        "\n",
        "Тем не менее существенных улучшений мне добиться не удалось, тестовая метрика accuracy в большинстве случаев остается в диапазоне 0.945-0.955, а главной проблемой, на мой взгляд, является переобучение."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 62.411032,
      "end_time": "2022-07-15T01:12:20.799389",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-07-15T01:11:18.388357",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}