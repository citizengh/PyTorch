{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "69ef05ec",
      "metadata": {
        "papermill": {
          "duration": 0.012126,
          "end_time": "2022-07-18T22:40:40.394248",
          "exception": false,
          "start_time": "2022-07-18T22:40:40.382122",
          "status": "completed"
        },
        "tags": [],
        "id": "69ef05ec"
      },
      "source": [
        "## Домашнее задание 7.\n",
        "\n",
        "1. Попробуйте обучить нейронную сеть GRU/LSTM для предсказания сентимента сообщений с твитера на примере https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n",
        "\n",
        "2. Опишите, какой результат вы получили? Что помогло вам улучшить ее точность?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a5ee7e",
      "metadata": {
        "papermill": {
          "duration": 0.010974,
          "end_time": "2022-07-18T22:40:40.416696",
          "exception": false,
          "start_time": "2022-07-18T22:40:40.405722",
          "status": "completed"
        },
        "tags": [],
        "id": "79a5ee7e"
      },
      "source": [
        "## Решение"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8317d9e",
      "metadata": {
        "papermill": {
          "duration": 0.010842,
          "end_time": "2022-07-18T22:40:40.439418",
          "exception": false,
          "start_time": "2022-07-18T22:40:40.428576",
          "status": "completed"
        },
        "tags": [],
        "id": "d8317d9e"
      },
      "source": [
        "Импортируем библиотеки, которые будут необходимы при дальнейшем решении задачи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fd2716",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:40.467363Z",
          "iopub.status.busy": "2022-07-18T22:40:40.466641Z",
          "iopub.status.idle": "2022-07-18T22:40:45.033646Z",
          "shell.execute_reply": "2022-07-18T22:40:45.032602Z"
        },
        "papermill": {
          "duration": 4.583092,
          "end_time": "2022-07-18T22:40:45.035993",
          "exception": false,
          "start_time": "2022-07-18T22:40:40.452901",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2fd2716",
        "outputId": "7f0b002c-4e50-4b03-d565-3f5b4887392b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from string import punctuation\n",
        "from textblob import TextBlob, Word\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from itertools import islice\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ebf9e80",
      "metadata": {
        "papermill": {
          "duration": 0.011251,
          "end_time": "2022-07-18T22:40:45.058649",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.047398",
          "status": "completed"
        },
        "tags": [],
        "id": "8ebf9e80"
      },
      "source": [
        "Проверка на наличие видеокарты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f29b309",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.083731Z",
          "iopub.status.busy": "2022-07-18T22:40:45.083163Z",
          "iopub.status.idle": "2022-07-18T22:40:45.145243Z",
          "shell.execute_reply": "2022-07-18T22:40:45.144204Z"
        },
        "papermill": {
          "duration": 0.077026,
          "end_time": "2022-07-18T22:40:45.147428",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.070402",
          "status": "completed"
        },
        "tags": [],
        "id": "3f29b309",
        "outputId": "070482bc-6bf6-48c8-fce2-10f9e7ec82f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/drive')"
      ],
      "metadata": {
        "id": "PgfgAgkT73Ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68602e50-5e35-4d10-8246-7bf2d68ff1b2"
      },
      "id": "PgfgAgkT73Ov",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d1d9249",
      "metadata": {
        "papermill": {
          "duration": 0.011618,
          "end_time": "2022-07-18T22:40:45.170565",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.158947",
          "status": "completed"
        },
        "tags": [],
        "id": "5d1d9249"
      },
      "source": [
        "Зададим ряд гиперпараметров, которые будут использоваться в дальнейшем процессе обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9817a9d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.198612Z",
          "iopub.status.busy": "2022-07-18T22:40:45.197961Z",
          "iopub.status.idle": "2022-07-18T22:40:45.203263Z",
          "shell.execute_reply": "2022-07-18T22:40:45.202101Z"
        },
        "papermill": {
          "duration": 0.021909,
          "end_time": "2022-07-18T22:40:45.205491",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.183582",
          "status": "completed"
        },
        "tags": [],
        "id": "b9817a9d"
      },
      "outputs": [],
      "source": [
        "max_words = 1500\n",
        "max_len = 15\n",
        "num_classes = 1\n",
        "batch_size = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f10fef57",
      "metadata": {
        "papermill": {
          "duration": 0.011415,
          "end_time": "2022-07-18T22:40:45.229577",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.218162",
          "status": "completed"
        },
        "tags": [],
        "id": "f10fef57"
      },
      "source": [
        "Считываем тренировочный датасет, на основе которого будем обучать нейросеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1036d05",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.257932Z",
          "iopub.status.busy": "2022-07-18T22:40:45.257101Z",
          "iopub.status.idle": "2022-07-18T22:40:45.411134Z",
          "shell.execute_reply": "2022-07-18T22:40:45.410076Z"
        },
        "papermill": {
          "duration": 0.171626,
          "end_time": "2022-07-18T22:40:45.413879",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.242253",
          "status": "completed"
        },
        "tags": [],
        "id": "d1036d05",
        "outputId": "14fac835-e950-4f0f-c974-f307f0f22b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab81fab3-e2fe-459a-9841-b1f21b1de9f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab81fab3-e2fe-459a-9841-b1f21b1de9f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab81fab3-e2fe-459a-9841-b1f21b1de9f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab81fab3-e2fe-459a-9841-b1f21b1de9f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "DATA_ROOT = '/drive/MyDrive/!!GeekBrains/31 Pythoch для разработки ИНС/!Пономарева/6 Нейросети в обработке текста'\n",
        "\n",
        "df_train = pd.read_csv(DATA_ROOT + \"/train.csv\")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95eff062",
      "metadata": {
        "papermill": {
          "duration": 0.012906,
          "end_time": "2022-07-18T22:40:45.439701",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.426795",
          "status": "completed"
        },
        "tags": [],
        "id": "95eff062"
      },
      "source": [
        "В данном случае мы имеем дело с несбалансированным датасетом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3bd548",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.466149Z",
          "iopub.status.busy": "2022-07-18T22:40:45.465743Z",
          "iopub.status.idle": "2022-07-18T22:40:45.479923Z",
          "shell.execute_reply": "2022-07-18T22:40:45.478778Z"
        },
        "papermill": {
          "duration": 0.0318,
          "end_time": "2022-07-18T22:40:45.483802",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.452002",
          "status": "completed"
        },
        "tags": [],
        "id": "4c3bd548",
        "outputId": "4596d4d6-2e78-4f56-c09c-6bc9f67c6eb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce094345",
      "metadata": {
        "papermill": {
          "duration": 0.012092,
          "end_time": "2022-07-18T22:40:45.508377",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.496285",
          "status": "completed"
        },
        "tags": [],
        "id": "ce094345"
      },
      "source": [
        "Сразу разделим данные на обучающий и валидационный наборы, добавим стратификацию, чтобы сохранить пропорции классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944e212d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.534887Z",
          "iopub.status.busy": "2022-07-18T22:40:45.534133Z",
          "iopub.status.idle": "2022-07-18T22:40:45.558105Z",
          "shell.execute_reply": "2022-07-18T22:40:45.556963Z"
        },
        "papermill": {
          "duration": 0.040045,
          "end_time": "2022-07-18T22:40:45.560798",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.520753",
          "status": "completed"
        },
        "tags": [],
        "id": "944e212d"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df_train['tweet'], \n",
        "                                                  df_train['label'], \n",
        "                                                  test_size=0.3, \n",
        "                                                  random_state=42, \n",
        "                                                  stratify=df_train['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d32ce2c8",
      "metadata": {
        "papermill": {
          "duration": 0.011882,
          "end_time": "2022-07-18T22:40:45.584656",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.572774",
          "status": "completed"
        },
        "tags": [],
        "id": "d32ce2c8"
      },
      "source": [
        "Теперь перейдем к предобработке твитов. Для начала сформируем множество стоп слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0fddb0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.611132Z",
          "iopub.status.busy": "2022-07-18T22:40:45.610747Z",
          "iopub.status.idle": "2022-07-18T22:40:45.626162Z",
          "shell.execute_reply": "2022-07-18T22:40:45.625092Z"
        },
        "papermill": {
          "duration": 0.03145,
          "end_time": "2022-07-18T22:40:45.628351",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.596901",
          "status": "completed"
        },
        "tags": [],
        "id": "4a0fddb0",
        "outputId": "4a842792-8d7f-48a2-b5d6-b6de0d7f7bbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'amp',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 'user',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sw = set(stopwords.words(\"english\"))\n",
        "# Добавим к стандартному множеству еще одно слово, которое не несет смысловой нагрузки,\n",
        "# но часто встречается как текстовое представление символа - &amp; \n",
        "sw.add('amp')\n",
        "# Добавим user, так как в данном датасете это является обезличенным \n",
        "# упоминанием пользователя в твите\n",
        "sw.add('user')\n",
        "sw"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feddeec1",
      "metadata": {
        "papermill": {
          "duration": 0.01254,
          "end_time": "2022-07-18T22:40:45.653258",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.640718",
          "status": "completed"
        },
        "tags": [],
        "id": "feddeec1"
      },
      "source": [
        "Сформируем дополнительно список знаков пунктуации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c789bd44",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.681369Z",
          "iopub.status.busy": "2022-07-18T22:40:45.679622Z",
          "iopub.status.idle": "2022-07-18T22:40:45.687334Z",
          "shell.execute_reply": "2022-07-18T22:40:45.686382Z"
        },
        "papermill": {
          "duration": 0.023649,
          "end_time": "2022-07-18T22:40:45.689342",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.665693",
          "status": "completed"
        },
        "tags": [],
        "id": "c789bd44",
        "outputId": "afc10eb5-dd32-4f53-be4e-e58e8fbceab1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "puncts = set(punctuation)\n",
        "puncts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b19c20",
      "metadata": {
        "papermill": {
          "duration": 0.011909,
          "end_time": "2022-07-18T22:40:45.713315",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.701406",
          "status": "completed"
        },
        "tags": [],
        "id": "08b19c20"
      },
      "source": [
        "Напишем функцию по аналогии с представленной на лекции, которая будет производить предобработку подаваемого текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eeaf27f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.740303Z",
          "iopub.status.busy": "2022-07-18T22:40:45.739302Z",
          "iopub.status.idle": "2022-07-18T22:40:45.747746Z",
          "shell.execute_reply": "2022-07-18T22:40:45.746563Z"
        },
        "papermill": {
          "duration": 0.024091,
          "end_time": "2022-07-18T22:40:45.749975",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.725884",
          "status": "completed"
        },
        "tags": [],
        "id": "0eeaf27f"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    # уберем нечитаемые символы типа  ð\\x9f¤\\x97\n",
        "    txt = \"\".join([c for c in txt if ord(c) < 128])\n",
        "    txt = \"\".join(c for c in txt if c not in puncts)\n",
        "    txt = txt.lower()\n",
        "    # преобразуем отрицания\n",
        "    txt = re.sub(\"not\\s\", \"not\", txt)\n",
        "    txt = re.sub(\"no\\s\", \"no\", txt)\n",
        "    # будем приводить формы к глаголам\n",
        "    txt = [Word(word).lemmatize('v') for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb89704",
      "metadata": {
        "papermill": {
          "duration": 0.012221,
          "end_time": "2022-07-18T22:40:45.774504",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.762283",
          "status": "completed"
        },
        "tags": [],
        "id": "2fb89704"
      },
      "source": [
        "Посмотрим на примерах на результат работы предобработки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d56c18",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.800971Z",
          "iopub.status.busy": "2022-07-18T22:40:45.800192Z",
          "iopub.status.idle": "2022-07-18T22:40:45.807297Z",
          "shell.execute_reply": "2022-07-18T22:40:45.806299Z"
        },
        "papermill": {
          "duration": 0.02298,
          "end_time": "2022-07-18T22:40:45.809631",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.786651",
          "status": "completed"
        },
        "tags": [],
        "id": "44d56c18",
        "outputId": "7f2fd134-d1d4-4cd7-eb4c-c11fd2949ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy bihday to my brother man. needed this mixtape like we need boos. have a good one sach   @user ',\n",
              "       '  lang to sta the week right :)  #happiness #smile ',\n",
              "       'note it meditate on it work on it ,but most impoantly trust god for it #icantwaitfohedayhisplansformylifeunfold #grateful  ',\n",
              "       '@user listening to you this wet mon, ahead of #leedsmillenium gig next month   ð\\x9f\\x98\\x86ð\\x9f\\x91\\x8dð\\x9f\\x98\\x8d #music #ace ',\n",
              "       '@user @user agreed.. the same is true for  and .. they are overused terms, and as a result, are fast becominâ\\x80¦',\n",
              "       'very exciting! #dubllife #recycle ',\n",
              "       '#bad times #drink   #nobev ',\n",
              "       '#ootd #converse #denim #tshi  #shopping  #like4like #l4l #f4f #instagood  ',\n",
              "       '  #fathersday to the man of my dreams! you sacrificed bachelorhood for a ready-made familyâ\\x80¦ ',\n",
              "       '  #pougalday #pay #saturday #fresh #new #haircut &amp; new #red #car in #style #chillingâ\\x80¦ '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_train.iloc[:10].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3815544",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:45.835987Z",
          "iopub.status.busy": "2022-07-18T22:40:45.835268Z",
          "iopub.status.idle": "2022-07-18T22:40:47.634073Z",
          "shell.execute_reply": "2022-07-18T22:40:47.633105Z"
        },
        "papermill": {
          "duration": 1.81463,
          "end_time": "2022-07-18T22:40:47.636574",
          "exception": false,
          "start_time": "2022-07-18T22:40:45.821944",
          "status": "completed"
        },
        "tags": [],
        "id": "b3815544",
        "outputId": "655d01a5-d434-4af8-acdd-3fa5c7dcbfff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['happy bihday brother man need mixtape like need boo good one sach',\n",
              "       'lang sta week right happiness smile',\n",
              "       'note meditate work impoantly trust god icantwaitfohedayhisplansformylifeunfold grateful',\n",
              "       'listen wet mon ahead leedsmillenium gig next month music ace',\n",
              "       'agree true overuse term result fast becomin',\n",
              "       'excite dubllife recycle', 'bad time drink nobev',\n",
              "       'ootd converse denim tshi shop like4like l4l f4f instagood',\n",
              "       'fathersday man dream sacrifice bachelorhood readymade family',\n",
              "       'pougalday pay saturday fresh new haircut new red car style chill'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train.iloc[:10].apply(preprocess_text).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "929b77aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-14T23:32:58.963688Z",
          "iopub.status.busy": "2022-07-14T23:32:58.963076Z",
          "iopub.status.idle": "2022-07-14T23:32:58.971592Z",
          "shell.execute_reply": "2022-07-14T23:32:58.97008Z",
          "shell.execute_reply.started": "2022-07-14T23:32:58.963653Z"
        },
        "papermill": {
          "duration": 0.012059,
          "end_time": "2022-07-18T22:40:47.661295",
          "exception": false,
          "start_time": "2022-07-18T22:40:47.649236",
          "status": "completed"
        },
        "tags": [],
        "id": "929b77aa"
      },
      "source": [
        "Теперь преобразуем тексты всех твитов с помощью данной функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2057923",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:47.688257Z",
          "iopub.status.busy": "2022-07-18T22:40:47.687419Z",
          "iopub.status.idle": "2022-07-18T22:40:50.412040Z",
          "shell.execute_reply": "2022-07-18T22:40:50.410955Z"
        },
        "papermill": {
          "duration": 2.740915,
          "end_time": "2022-07-18T22:40:50.414581",
          "exception": false,
          "start_time": "2022-07-18T22:40:47.673666",
          "status": "completed"
        },
        "tags": [],
        "id": "c2057923"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(preprocess_text).values\n",
        "X_val = X_val.apply(preprocess_text).values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "764ebe91",
      "metadata": {
        "papermill": {
          "duration": 0.013224,
          "end_time": "2022-07-18T22:40:50.440576",
          "exception": false,
          "start_time": "2022-07-18T22:40:50.427352",
          "status": "completed"
        },
        "tags": [],
        "id": "764ebe91"
      },
      "source": [
        "Перейдем к реализации процесса токенизации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f335eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:50.467332Z",
          "iopub.status.busy": "2022-07-18T22:40:50.466713Z",
          "iopub.status.idle": "2022-07-18T22:40:50.475962Z",
          "shell.execute_reply": "2022-07-18T22:40:50.475001Z"
        },
        "papermill": {
          "duration": 0.025098,
          "end_time": "2022-07-18T22:40:50.478249",
          "exception": false,
          "start_time": "2022-07-18T22:40:50.453151",
          "status": "completed"
        },
        "tags": [],
        "id": "f9f335eb"
      },
      "outputs": [],
      "source": [
        "train_corpus = \" \".join(X_train)\n",
        "train_corpus = train_corpus.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b639033",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:50.505355Z",
          "iopub.status.busy": "2022-07-18T22:40:50.504317Z",
          "iopub.status.idle": "2022-07-18T22:40:52.025236Z",
          "shell.execute_reply": "2022-07-18T22:40:52.024227Z"
        },
        "papermill": {
          "duration": 1.536892,
          "end_time": "2022-07-18T22:40:52.027416",
          "exception": false,
          "start_time": "2022-07-18T22:40:50.490524",
          "status": "completed"
        },
        "tags": [],
        "id": "0b639033",
        "outputId": "99d88f2d-d101-455b-e5d0-86f9e9de9a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['happy', 'bihday', 'brother', 'man', 'need']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "325ac4f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:52.056410Z",
          "iopub.status.busy": "2022-07-18T22:40:52.054603Z",
          "iopub.status.idle": "2022-07-18T22:40:52.217489Z",
          "shell.execute_reply": "2022-07-18T22:40:52.216447Z"
        },
        "papermill": {
          "duration": 0.17943,
          "end_time": "2022-07-18T22:40:52.219672",
          "exception": false,
          "start_time": "2022-07-18T22:40:52.040242",
          "status": "completed"
        },
        "tags": [],
        "id": "325ac4f8",
        "outputId": "43b11424-b9c7-4f5d-bc27-f1b311db3b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love', 'day', 'get', 'happy', 'go', 'time', 'make', 'im', 'u', 'life']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
        "\n",
        "# Посмотрим на топ 10 слов\n",
        "tokens_filtered_top[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044445f0",
      "metadata": {
        "papermill": {
          "duration": 0.012498,
          "end_time": "2022-07-18T22:40:52.244867",
          "exception": false,
          "start_time": "2022-07-18T22:40:52.232369",
          "status": "completed"
        },
        "tags": [],
        "id": "044445f0"
      },
      "source": [
        "Сформируем словарь, в котором будут храниться наиболее часто встречающиеся слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0834f165",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:52.272907Z",
          "iopub.status.busy": "2022-07-18T22:40:52.272151Z",
          "iopub.status.idle": "2022-07-18T22:40:52.282133Z",
          "shell.execute_reply": "2022-07-18T22:40:52.280968Z"
        },
        "papermill": {
          "duration": 0.026584,
          "end_time": "2022-07-18T22:40:52.284414",
          "exception": false,
          "start_time": "2022-07-18T22:40:52.257830",
          "status": "completed"
        },
        "tags": [],
        "id": "0834f165",
        "outputId": "f6bf6a8c-5ed0-48e7-a23f-7a9a127969b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 1),\n",
              " ('day', 2),\n",
              " ('get', 3),\n",
              " ('happy', 4),\n",
              " ('go', 5),\n",
              " ('time', 6),\n",
              " ('make', 7),\n",
              " ('im', 8),\n",
              " ('u', 9),\n",
              " ('life', 10),\n",
              " ('like', 11),\n",
              " ('today', 12),\n",
              " ('new', 13),\n",
              " ('father', 14),\n",
              " ('see', 15),\n",
              " ('positive', 16),\n",
              " ('smile', 17),\n",
              " ('thankful', 18),\n",
              " ('people', 19),\n",
              " ('bihday', 20)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def take(n, iterable):\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
        "take(20, vocabulary.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "900a7449",
      "metadata": {
        "papermill": {
          "duration": 0.012086,
          "end_time": "2022-07-18T22:40:52.309058",
          "exception": false,
          "start_time": "2022-07-18T22:40:52.296972",
          "status": "completed"
        },
        "tags": [],
        "id": "900a7449"
      },
      "source": [
        "Запишем функцию преобразования текста в токены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531c7852",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:52.335978Z",
          "iopub.status.busy": "2022-07-18T22:40:52.334992Z",
          "iopub.status.idle": "2022-07-18T22:40:52.342155Z",
          "shell.execute_reply": "2022-07-18T22:40:52.341239Z"
        },
        "papermill": {
          "duration": 0.022834,
          "end_time": "2022-07-18T22:40:52.344273",
          "exception": false,
          "start_time": "2022-07-18T22:40:52.321439",
          "status": "completed"
        },
        "tags": [],
        "id": "531c7852"
      },
      "outputs": [],
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "    return result[-maxlen:] + padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc155966",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:52.372284Z",
          "iopub.status.busy": "2022-07-18T22:40:52.371142Z",
          "iopub.status.idle": "2022-07-18T22:40:57.818545Z",
          "shell.execute_reply": "2022-07-18T22:40:57.817397Z"
        },
        "papermill": {
          "duration": 5.464619,
          "end_time": "2022-07-18T22:40:57.821598",
          "exception": false,
          "start_time": "2022-07-18T22:40:52.356979",
          "status": "completed"
        },
        "tags": [],
        "id": "dc155966",
        "outputId": "fbfa9e5d-35b4-4f96-d123-e77954c851e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.29 s, sys: 584 µs, total: 4.29 s\n",
            "Wall time: 4.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train])\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in X_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc31e5de",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:57.849914Z",
          "iopub.status.busy": "2022-07-18T22:40:57.848870Z",
          "iopub.status.idle": "2022-07-18T22:40:57.856155Z",
          "shell.execute_reply": "2022-07-18T22:40:57.855030Z"
        },
        "papermill": {
          "duration": 0.023716,
          "end_time": "2022-07-18T22:40:57.858319",
          "exception": false,
          "start_time": "2022-07-18T22:40:57.834603",
          "status": "completed"
        },
        "tags": [],
        "id": "fc31e5de",
        "outputId": "c562e409-7583-4c09-a875-5bdfa829f196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([165,  69,  76,  77,  17,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x_train[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec62486c",
      "metadata": {
        "papermill": {
          "duration": 0.012869,
          "end_time": "2022-07-18T22:40:57.884097",
          "exception": false,
          "start_time": "2022-07-18T22:40:57.871228",
          "status": "completed"
        },
        "tags": [],
        "id": "ec62486c"
      },
      "source": [
        "Соберем сеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06337cc3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:57.912114Z",
          "iopub.status.busy": "2022-07-18T22:40:57.911185Z",
          "iopub.status.idle": "2022-07-18T22:40:57.920265Z",
          "shell.execute_reply": "2022-07-18T22:40:57.919149Z"
        },
        "papermill": {
          "duration": 0.024996,
          "end_time": "2022-07-18T22:40:57.922346",
          "exception": false,
          "start_time": "2022-07-18T22:40:57.897350",
          "status": "completed"
        },
        "tags": [],
        "id": "06337cc3"
      },
      "outputs": [],
      "source": [
        "class LSTMFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, drop_prob=0.1, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=drop_prob)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "#         self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "#         x = self.dropout(x)\n",
        "        lstm_out, ht = self.lstm(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = lstm_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(lstm_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98371b7f",
      "metadata": {
        "papermill": {
          "duration": 0.012831,
          "end_time": "2022-07-18T22:40:57.947875",
          "exception": false,
          "start_time": "2022-07-18T22:40:57.935044",
          "status": "completed"
        },
        "tags": [],
        "id": "98371b7f"
      },
      "source": [
        "Создадим класс датасета и определим даталоадеры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15e6887",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:57.975958Z",
          "iopub.status.busy": "2022-07-18T22:40:57.974950Z",
          "iopub.status.idle": "2022-07-18T22:40:57.983230Z",
          "shell.execute_reply": "2022-07-18T22:40:57.982213Z"
        },
        "papermill": {
          "duration": 0.025013,
          "end_time": "2022-07-18T22:40:57.985587",
          "exception": false,
          "start_time": "2022-07-18T22:40:57.960574",
          "status": "completed"
        },
        "tags": [],
        "id": "a15e6887"
      },
      "outputs": [],
      "source": [
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).long()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd6a419a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:58.012927Z",
          "iopub.status.busy": "2022-07-18T22:40:58.012570Z",
          "iopub.status.idle": "2022-07-18T22:40:58.018713Z",
          "shell.execute_reply": "2022-07-18T22:40:58.017724Z"
        },
        "papermill": {
          "duration": 0.02245,
          "end_time": "2022-07-18T22:40:58.020860",
          "exception": false,
          "start_time": "2022-07-18T22:40:57.998410",
          "status": "completed"
        },
        "tags": [],
        "id": "dd6a419a"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataWrapper(x_train, y_train.values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(x_val, y_val.values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74378e39",
      "metadata": {
        "papermill": {
          "duration": 0.012349,
          "end_time": "2022-07-18T22:40:58.045897",
          "exception": false,
          "start_time": "2022-07-18T22:40:58.033548",
          "status": "completed"
        },
        "tags": [],
        "id": "74378e39"
      },
      "source": [
        "Задаем критерий с учетом бинарности результатов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971a0709",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:58.073857Z",
          "iopub.status.busy": "2022-07-18T22:40:58.073499Z",
          "iopub.status.idle": "2022-07-18T22:40:58.078000Z",
          "shell.execute_reply": "2022-07-18T22:40:58.077038Z"
        },
        "papermill": {
          "duration": 0.020904,
          "end_time": "2022-07-18T22:40:58.080138",
          "exception": false,
          "start_time": "2022-07-18T22:40:58.059234",
          "status": "completed"
        },
        "tags": [],
        "id": "971a0709"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de66690",
      "metadata": {
        "papermill": {
          "duration": 0.013127,
          "end_time": "2022-07-18T22:40:58.106615",
          "exception": false,
          "start_time": "2022-07-18T22:40:58.093488",
          "status": "completed"
        },
        "tags": [],
        "id": "4de66690"
      },
      "source": [
        "Проведем перебор по сетке для определения оптимальных гиперпараметров модели LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22ee472",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:58.135173Z",
          "iopub.status.busy": "2022-07-18T22:40:58.134389Z",
          "iopub.status.idle": "2022-07-18T22:40:58.140560Z",
          "shell.execute_reply": "2022-07-18T22:40:58.139489Z"
        },
        "papermill": {
          "duration": 0.022993,
          "end_time": "2022-07-18T22:40:58.142913",
          "exception": false,
          "start_time": "2022-07-18T22:40:58.119920",
          "status": "completed"
        },
        "tags": [],
        "id": "b22ee472"
      },
      "outputs": [],
      "source": [
        "n_epochs = [5, 10]\n",
        "learning_rates = [1e-2, 1e-3]\n",
        "e_dims = [128, 256]\n",
        "h_dims = [64, 96]\n",
        "ths = [0.3, 0.5]\n",
        "dps = [0.1, 0.2, 0.3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c1548c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T22:40:58.170997Z",
          "iopub.status.busy": "2022-07-18T22:40:58.170032Z",
          "iopub.status.idle": "2022-07-18T23:03:23.321030Z",
          "shell.execute_reply": "2022-07-18T23:03:23.319802Z"
        },
        "papermill": {
          "duration": 1345.168419,
          "end_time": "2022-07-18T23:03:23.324109",
          "exception": false,
          "start_time": "2022-07-18T22:40:58.155690",
          "status": "completed"
        },
        "tags": [],
        "id": "6c1548c6",
        "outputId": "e87754fa-7e4b-441f-c529-224948cc64cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.231. Acc: 0.874. Test loss: 0.609.Test acc: 0.940\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.130. Acc: 0.946. Test loss: 0.014.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.120. Acc: 0.950. Test loss: 0.021.Test acc: 0.944\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.089. Acc: 0.962. Test loss: 0.029.Test acc: 0.943\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.060. Acc: 0.967. Test loss: 0.039.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.164. Acc: 0.872. Test loss: 0.048.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.171. Acc: 0.942. Test loss: 0.019.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.135. Acc: 0.955. Test loss: 0.008.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.126. Acc: 0.962. Test loss: 0.191.Test acc: 0.944\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.070. Acc: 0.966. Test loss: 0.001.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.125. Acc: 0.880. Test loss: 0.037.Test acc: 0.945\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.141. Acc: 0.945. Test loss: 0.348.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.175. Acc: 0.957. Test loss: 0.115.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.130. Acc: 0.964. Test loss: 0.035.Test acc: 0.949\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.108. Acc: 0.967. Test loss: 0.007.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.171. Acc: 0.935. Test loss: 0.027.Test acc: 0.942\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.128. Acc: 0.950. Test loss: 0.520.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.106. Acc: 0.960. Test loss: 0.015.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.097. Acc: 0.966. Test loss: 0.009.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.078. Acc: 0.972. Test loss: 0.002.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.226. Acc: 0.914. Test loss: 0.257.Test acc: 0.934\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.164. Acc: 0.933. Test loss: 0.022.Test acc: 0.930\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.186. Acc: 0.935. Test loss: 0.017.Test acc: 0.941\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.129. Acc: 0.951. Test loss: 0.070.Test acc: 0.949\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.101. Acc: 0.960. Test loss: 0.567.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.126. Acc: 0.929. Test loss: 0.030.Test acc: 0.940\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.180. Acc: 0.947. Test loss: 0.051.Test acc: 0.948\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.133. Acc: 0.956. Test loss: 0.038.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.071. Acc: 0.964. Test loss: 0.234.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.082. Acc: 0.969. Test loss: 0.042.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.197. Acc: 0.892. Test loss: 0.172.Test acc: 0.900\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.148. Acc: 0.920. Test loss: 0.019.Test acc: 0.937\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.121. Acc: 0.947. Test loss: 0.027.Test acc: 0.940\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.098. Acc: 0.955. Test loss: 0.004.Test acc: 0.938\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.090. Acc: 0.961. Test loss: 0.032.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.157. Acc: 0.894. Test loss: 0.020.Test acc: 0.942\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.140. Acc: 0.949. Test loss: 0.045.Test acc: 0.948\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.113. Acc: 0.959. Test loss: 0.028.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.075. Acc: 0.963. Test loss: 0.585.Test acc: 0.943\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.075. Acc: 0.971. Test loss: 0.836.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.165. Acc: 0.894. Test loss: 0.078.Test acc: 0.944\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.123. Acc: 0.949. Test loss: 0.085.Test acc: 0.940\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.140. Acc: 0.956. Test loss: 0.075.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.125. Acc: 0.962. Test loss: 0.005.Test acc: 0.947\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.097. Acc: 0.971. Test loss: 0.001.Test acc: 0.939\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.231. Acc: 0.934. Test loss: 0.174.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.153. Acc: 0.951. Test loss: 0.041.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.110. Acc: 0.960. Test loss: 0.007.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.965. Test loss: 0.007.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.110. Acc: 0.971. Test loss: 0.019.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.157. Acc: 0.918. Test loss: 0.156.Test acc: 0.947\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.140. Acc: 0.952. Test loss: 0.005.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.122. Acc: 0.961. Test loss: 0.101.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.098. Acc: 0.968. Test loss: 0.509.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.086. Acc: 0.973. Test loss: 0.027.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.153. Acc: 0.936. Test loss: 0.736.Test acc: 0.942\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.118. Acc: 0.951. Test loss: 0.004.Test acc: 0.949\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.143. Acc: 0.959. Test loss: 0.073.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.096. Acc: 0.966. Test loss: 0.109.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.077. Acc: 0.973. Test loss: 0.001.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.172. Acc: 0.852. Test loss: 0.048.Test acc: 0.926\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.205. Acc: 0.900. Test loss: 0.127.Test acc: 0.907\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.131. Acc: 0.932. Test loss: 0.035.Test acc: 0.930\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.159. Acc: 0.947. Test loss: 0.091.Test acc: 0.932\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.120. Acc: 0.959. Test loss: 0.087.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.125. Acc: 0.869. Test loss: 0.678.Test acc: 0.908\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.178. Acc: 0.919. Test loss: 0.119.Test acc: 0.919\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.153. Acc: 0.938. Test loss: 0.015.Test acc: 0.937\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.157. Acc: 0.949. Test loss: 0.018.Test acc: 0.942\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.115. Acc: 0.953. Test loss: 0.223.Test acc: 0.938\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.195. Acc: 0.869. Test loss: 0.170.Test acc: 0.926\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.160. Acc: 0.938. Test loss: 0.301.Test acc: 0.937\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.114. Acc: 0.948. Test loss: 0.142.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.109. Acc: 0.957. Test loss: 0.031.Test acc: 0.943\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.088. Acc: 0.963. Test loss: 0.005.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.186. Acc: 0.912. Test loss: 0.202.Test acc: 0.930\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.184. Acc: 0.936. Test loss: 0.159.Test acc: 0.933\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.120. Acc: 0.938. Test loss: 0.024.Test acc: 0.934\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.123. Acc: 0.949. Test loss: 0.126.Test acc: 0.948\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.100. Acc: 0.961. Test loss: 0.339.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.115. Acc: 0.918. Test loss: 0.035.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.122. Acc: 0.952. Test loss: 0.521.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.106. Acc: 0.962. Test loss: 0.003.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.078. Acc: 0.968. Test loss: 0.040.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.057. Acc: 0.973. Test loss: 0.040.Test acc: 0.953\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.151. Acc: 0.924. Test loss: 0.018.Test acc: 0.929\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.159. Acc: 0.945. Test loss: 0.039.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.136. Acc: 0.960. Test loss: 0.178.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.093. Acc: 0.968. Test loss: 0.539.Test acc: 0.949\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.068. Acc: 0.975. Test loss: 0.003.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.167. Acc: 0.892. Test loss: 0.026.Test acc: 0.924\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.102. Acc: 0.941. Test loss: 0.456.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.121. Acc: 0.954. Test loss: 0.045.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.110. Acc: 0.962. Test loss: 0.594.Test acc: 0.947\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.079. Acc: 0.968. Test loss: 0.029.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.135. Acc: 0.899. Test loss: 0.129.Test acc: 0.946\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.179. Acc: 0.951. Test loss: 0.007.Test acc: 0.948\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.118. Acc: 0.958. Test loss: 0.047.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.127. Acc: 0.967. Test loss: 0.007.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.057. Acc: 0.973. Test loss: 0.001.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.176. Acc: 0.895. Test loss: 0.022.Test acc: 0.930\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.145. Acc: 0.945. Test loss: 0.015.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.127. Acc: 0.956. Test loss: 0.375.Test acc: 0.948\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.128. Acc: 0.966. Test loss: 0.010.Test acc: 0.942\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.079. Acc: 0.970. Test loss: 0.002.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.165. Acc: 0.931. Test loss: 0.212.Test acc: 0.930\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.143. Acc: 0.941. Test loss: 0.492.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.153. Acc: 0.954. Test loss: 0.404.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.098. Acc: 0.962. Test loss: 0.095.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.105. Acc: 0.968. Test loss: 0.075.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.193. Acc: 0.940. Test loss: 0.868.Test acc: 0.946\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.092. Acc: 0.954. Test loss: 0.027.Test acc: 0.951\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.096. Acc: 0.964. Test loss: 0.008.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.096. Acc: 0.971. Test loss: 0.017.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.095. Acc: 0.977. Test loss: 0.001.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.202. Acc: 0.917. Test loss: 0.029.Test acc: 0.942\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.186. Acc: 0.947. Test loss: 0.025.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.115. Acc: 0.959. Test loss: 0.035.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.105. Acc: 0.968. Test loss: 0.006.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.088. Acc: 0.972. Test loss: 0.004.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.242. Acc: 0.586. Test loss: 0.042.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.168. Acc: 0.935. Test loss: 0.081.Test acc: 0.935\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.151. Acc: 0.942. Test loss: 0.034.Test acc: 0.938\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.139. Acc: 0.951. Test loss: 0.032.Test acc: 0.945\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.107. Acc: 0.957. Test loss: 0.157.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.222. Acc: 0.557. Test loss: 0.058.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.153. Acc: 0.936. Test loss: 0.113.Test acc: 0.938\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.137. Acc: 0.943. Test loss: 0.026.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.114. Acc: 0.950. Test loss: 0.275.Test acc: 0.941\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.115. Acc: 0.955. Test loss: 0.017.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.252. Acc: 0.550. Test loss: 0.616.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.178. Acc: 0.936. Test loss: 0.416.Test acc: 0.932\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.166. Acc: 0.944. Test loss: 0.112.Test acc: 0.940\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.951. Test loss: 0.808.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.108. Acc: 0.957. Test loss: 0.010.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.234. Acc: 0.930. Test loss: 0.064.Test acc: 0.930\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.156. Acc: 0.935. Test loss: 0.679.Test acc: 0.941\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.143. Acc: 0.947. Test loss: 0.032.Test acc: 0.946\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.135. Acc: 0.953. Test loss: 0.037.Test acc: 0.949\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.137. Acc: 0.959. Test loss: 0.728.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.194. Acc: 0.924. Test loss: 0.045.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.198. Acc: 0.937. Test loss: 1.320.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.177. Acc: 0.948. Test loss: 0.420.Test acc: 0.948\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.184. Acc: 0.955. Test loss: 0.027.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.135. Acc: 0.959. Test loss: 0.921.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.183. Acc: 0.930. Test loss: 0.613.Test acc: 0.930\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.172. Acc: 0.934. Test loss: 0.030.Test acc: 0.941\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.156. Acc: 0.948. Test loss: 0.058.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.118. Acc: 0.952. Test loss: 0.013.Test acc: 0.947\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.106. Acc: 0.958. Test loss: 0.587.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.238. Acc: 0.635. Test loss: 0.608.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.142. Acc: 0.940. Test loss: 0.049.Test acc: 0.940\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.162. Acc: 0.948. Test loss: 0.056.Test acc: 0.944\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.140. Acc: 0.954. Test loss: 0.031.Test acc: 0.944\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.168. Acc: 0.958. Test loss: 0.009.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.200. Acc: 0.671. Test loss: 0.057.Test acc: 0.937\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.142. Acc: 0.938. Test loss: 0.030.Test acc: 0.938\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.147. Acc: 0.945. Test loss: 0.037.Test acc: 0.942\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.122. Acc: 0.952. Test loss: 0.026.Test acc: 0.942\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.192. Acc: 0.956. Test loss: 0.025.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.241. Acc: 0.656. Test loss: 0.070.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.196. Acc: 0.938. Test loss: 0.053.Test acc: 0.941\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.160. Acc: 0.946. Test loss: 0.024.Test acc: 0.942\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.128. Acc: 0.953. Test loss: 0.018.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.152. Acc: 0.958. Test loss: 0.653.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.219. Acc: 0.869. Test loss: 0.651.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.115. Acc: 0.941. Test loss: 0.035.Test acc: 0.942\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.126. Acc: 0.951. Test loss: 0.312.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.113. Acc: 0.958. Test loss: 0.019.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.109. Acc: 0.962. Test loss: 0.077.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.245. Acc: 0.929. Test loss: 0.572.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.128. Acc: 0.938. Test loss: 0.168.Test acc: 0.943\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.136. Acc: 0.948. Test loss: 0.124.Test acc: 0.947\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.137. Acc: 0.956. Test loss: 0.235.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.117. Acc: 0.960. Test loss: 0.028.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.176. Acc: 0.931. Test loss: 0.072.Test acc: 0.934\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.175. Acc: 0.940. Test loss: 0.040.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.169. Acc: 0.950. Test loss: 0.052.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.123. Acc: 0.957. Test loss: 0.014.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.121. Acc: 0.962. Test loss: 0.097.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.270. Acc: 0.599. Test loss: 0.658.Test acc: 0.935\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.209. Acc: 0.939. Test loss: 0.025.Test acc: 0.937\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.126. Acc: 0.949. Test loss: 0.032.Test acc: 0.941\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.095. Acc: 0.958. Test loss: 0.923.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.138. Acc: 0.963. Test loss: 0.104.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.275. Acc: 0.610. Test loss: 1.321.Test acc: 0.934\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.141. Acc: 0.941. Test loss: 0.025.Test acc: 0.936\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.186. Acc: 0.948. Test loss: 0.014.Test acc: 0.941\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.072. Acc: 0.956. Test loss: 0.440.Test acc: 0.943\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.118. Acc: 0.963. Test loss: 0.011.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.321. Acc: 0.555. Test loss: 0.598.Test acc: 0.933\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.215. Acc: 0.939. Test loss: 0.040.Test acc: 0.934\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.145. Acc: 0.945. Test loss: 0.763.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.169. Acc: 0.957. Test loss: 0.019.Test acc: 0.940\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.110. Acc: 0.962. Test loss: 0.029.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.215. Acc: 0.930. Test loss: 0.686.Test acc: 0.933\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.175. Acc: 0.941. Test loss: 0.020.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.134. Acc: 0.954. Test loss: 0.150.Test acc: 0.948\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.110. Acc: 0.960. Test loss: 0.010.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.097. Acc: 0.966. Test loss: 0.013.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.229. Acc: 0.905. Test loss: 0.043.Test acc: 0.930\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.152. Acc: 0.937. Test loss: 0.037.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.151. Acc: 0.952. Test loss: 0.027.Test acc: 0.948\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.138. Acc: 0.960. Test loss: 0.310.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.106. Acc: 0.966. Test loss: 0.791.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.237. Acc: 0.930. Test loss: 0.667.Test acc: 0.933\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.189. Acc: 0.939. Test loss: 0.029.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.156. Acc: 0.952. Test loss: 0.021.Test acc: 0.946\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.114. Acc: 0.959. Test loss: 0.151.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.115. Acc: 0.964. Test loss: 0.025.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.206. Acc: 0.670. Test loss: 0.078.Test acc: 0.943\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.108. Acc: 0.944. Test loss: 0.030.Test acc: 0.943\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.140. Acc: 0.950. Test loss: 0.008.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.109. Acc: 0.959. Test loss: 0.035.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.072. Acc: 0.966. Test loss: 0.011.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.202. Acc: 0.677. Test loss: 0.061.Test acc: 0.943\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.172. Acc: 0.942. Test loss: 0.655.Test acc: 0.940\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.098. Acc: 0.951. Test loss: 0.636.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.109. Acc: 0.960. Test loss: 0.545.Test acc: 0.944\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.123. Acc: 0.964. Test loss: 0.050.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.226. Acc: 0.664. Test loss: 0.082.Test acc: 0.940\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.127. Acc: 0.943. Test loss: 0.803.Test acc: 0.936\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.170. Acc: 0.952. Test loss: 0.430.Test acc: 0.944\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.100. Acc: 0.958. Test loss: 0.442.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.156. Acc: 0.964. Test loss: 0.201.Test acc: 0.940\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.180. Acc: 0.931. Test loss: 0.078.Test acc: 0.938\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.170. Acc: 0.946. Test loss: 0.026.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.115. Acc: 0.956. Test loss: 0.015.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.140. Acc: 0.963. Test loss: 0.023.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.097. Acc: 0.968. Test loss: 0.007.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.253. Acc: 0.932. Test loss: 0.065.Test acc: 0.935\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.153. Acc: 0.944. Test loss: 0.031.Test acc: 0.949\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.165. Acc: 0.955. Test loss: 0.011.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.109. Acc: 0.962. Test loss: 0.463.Test acc: 0.948\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.157. Acc: 0.968. Test loss: 0.018.Test acc: 0.953\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.215. Acc: 0.899. Test loss: 0.065.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.110. Acc: 0.944. Test loss: 0.029.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.158. Acc: 0.954. Test loss: 0.203.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.181. Acc: 0.960. Test loss: 0.021.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.110. Acc: 0.966. Test loss: 0.008.Test acc: 0.954\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.142. Acc: 0.894. Test loss: 0.022.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.149. Acc: 0.950. Test loss: 0.991.Test acc: 0.947\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.135. Acc: 0.958. Test loss: 0.746.Test acc: 0.940\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.126. Acc: 0.964. Test loss: 0.042.Test acc: 0.936\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.083. Acc: 0.968. Test loss: 0.066.Test acc: 0.943\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.083. Acc: 0.973. Test loss: 0.271.Test acc: 0.941\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.053. Acc: 0.980. Test loss: 1.326.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.054. Acc: 0.982. Test loss: 0.000.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.022. Acc: 0.985. Test loss: 0.486.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.075. Acc: 0.987. Test loss: 0.110.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.214. Acc: 0.867. Test loss: 0.187.Test acc: 0.914\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.212. Acc: 0.931. Test loss: 0.649.Test acc: 0.936\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.101. Acc: 0.944. Test loss: 0.013.Test acc: 0.942\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.080. Acc: 0.956. Test loss: 0.023.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.075. Acc: 0.963. Test loss: 0.002.Test acc: 0.943\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.086. Acc: 0.968. Test loss: 0.047.Test acc: 0.946\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.084. Acc: 0.972. Test loss: 0.009.Test acc: 0.936\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.089. Acc: 0.974. Test loss: 0.005.Test acc: 0.937\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.061. Acc: 0.980. Test loss: 0.067.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.043. Acc: 0.984. Test loss: 1.651.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.167. Acc: 0.868. Test loss: 0.037.Test acc: 0.929\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.195. Acc: 0.939. Test loss: 0.050.Test acc: 0.927\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.126. Acc: 0.950. Test loss: 0.062.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.121. Acc: 0.960. Test loss: 0.040.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.093. Acc: 0.964. Test loss: 0.082.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.088. Acc: 0.969. Test loss: 0.001.Test acc: 0.945\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.050. Acc: 0.975. Test loss: 0.001.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.058. Acc: 0.979. Test loss: 0.911.Test acc: 0.939\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.054. Acc: 0.984. Test loss: 0.002.Test acc: 0.939\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.047. Acc: 0.986. Test loss: 0.040.Test acc: 0.938\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.183. Acc: 0.919. Test loss: 0.617.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.158. Acc: 0.950. Test loss: 0.017.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.157. Acc: 0.958. Test loss: 0.041.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.121. Acc: 0.965. Test loss: 0.022.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.117. Acc: 0.972. Test loss: 0.015.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.096. Acc: 0.976. Test loss: 0.057.Test acc: 0.945\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.115. Acc: 0.979. Test loss: 0.014.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.035. Acc: 0.981. Test loss: 0.033.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.056. Acc: 0.984. Test loss: 0.081.Test acc: 0.950\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.057. Acc: 0.986. Test loss: 0.155.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.216. Acc: 0.910. Test loss: 0.219.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.144. Acc: 0.938. Test loss: 0.030.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.153. Acc: 0.953. Test loss: 0.067.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.098. Acc: 0.960. Test loss: 1.082.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.152. Acc: 0.968. Test loss: 0.422.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.101. Acc: 0.971. Test loss: 0.004.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.064. Acc: 0.972. Test loss: 0.002.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.062. Acc: 0.978. Test loss: 0.018.Test acc: 0.946\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.046. Acc: 0.982. Test loss: 0.000.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.076. Acc: 0.986. Test loss: 0.361.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.209. Acc: 0.915. Test loss: 0.040.Test acc: 0.938\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.162. Acc: 0.943. Test loss: 0.176.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.123. Acc: 0.954. Test loss: 0.272.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.081. Acc: 0.961. Test loss: 0.579.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.074. Acc: 0.966. Test loss: 1.024.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.114. Acc: 0.970. Test loss: 0.042.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.081. Acc: 0.972. Test loss: 0.093.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.082. Acc: 0.969. Test loss: 0.219.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.043. Acc: 0.974. Test loss: 0.055.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.050. Acc: 0.980. Test loss: 0.072.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.198. Acc: 0.893. Test loss: 0.037.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.130. Acc: 0.947. Test loss: 0.019.Test acc: 0.951\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.128. Acc: 0.958. Test loss: 0.008.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.070. Acc: 0.964. Test loss: 0.007.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.065. Acc: 0.970. Test loss: 0.001.Test acc: 0.946\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.069. Acc: 0.977. Test loss: 0.048.Test acc: 0.938\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.041. Acc: 0.982. Test loss: 0.020.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.059. Acc: 0.985. Test loss: 0.323.Test acc: 0.929\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.026. Acc: 0.988. Test loss: 2.638.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.031. Acc: 0.988. Test loss: 1.693.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.230. Acc: 0.881. Test loss: 0.038.Test acc: 0.904\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.134. Acc: 0.917. Test loss: 0.031.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.093. Acc: 0.946. Test loss: 0.015.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.131. Acc: 0.953. Test loss: 0.057.Test acc: 0.927\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.122. Acc: 0.960. Test loss: 0.036.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.119. Acc: 0.967. Test loss: 0.005.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.067. Acc: 0.972. Test loss: 1.410.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.071. Acc: 0.978. Test loss: 0.594.Test acc: 0.931\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.066. Acc: 0.982. Test loss: 0.014.Test acc: 0.936\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.051. Acc: 0.984. Test loss: 0.013.Test acc: 0.939\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.127. Acc: 0.900. Test loss: 0.035.Test acc: 0.943\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.144. Acc: 0.947. Test loss: 0.023.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.110. Acc: 0.955. Test loss: 0.048.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.095. Acc: 0.961. Test loss: 0.081.Test acc: 0.938\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.047. Acc: 0.967. Test loss: 0.053.Test acc: 0.946\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.077. Acc: 0.973. Test loss: 0.001.Test acc: 0.946\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.046. Acc: 0.979. Test loss: 0.001.Test acc: 0.944\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.056. Acc: 0.984. Test loss: 0.009.Test acc: 0.939\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.070. Acc: 0.986. Test loss: 0.807.Test acc: 0.944\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.018. Acc: 0.990. Test loss: 0.001.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.182. Acc: 0.919. Test loss: 0.773.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.168. Acc: 0.938. Test loss: 0.085.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.185. Acc: 0.950. Test loss: 0.635.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.115. Acc: 0.955. Test loss: 0.004.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.108. Acc: 0.963. Test loss: 0.117.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.109. Acc: 0.968. Test loss: 0.015.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.084. Acc: 0.976. Test loss: 0.124.Test acc: 0.952\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.052. Acc: 0.981. Test loss: 0.002.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.036. Acc: 0.984. Test loss: 0.369.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.031. Acc: 0.987. Test loss: 0.019.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.191. Acc: 0.918. Test loss: 0.050.Test acc: 0.947\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.121. Acc: 0.951. Test loss: 0.021.Test acc: 0.949\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.130. Acc: 0.960. Test loss: 0.020.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.075. Acc: 0.967. Test loss: 0.065.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.085. Acc: 0.971. Test loss: 0.042.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.060. Acc: 0.975. Test loss: 0.149.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.073. Acc: 0.980. Test loss: 1.305.Test acc: 0.952\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.047. Acc: 0.984. Test loss: 0.000.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.056. Acc: 0.987. Test loss: 0.388.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.054. Acc: 0.989. Test loss: 0.001.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.168. Acc: 0.936. Test loss: 0.032.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.123. Acc: 0.951. Test loss: 0.637.Test acc: 0.950\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.126. Acc: 0.960. Test loss: 0.019.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.086. Acc: 0.967. Test loss: 0.291.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.082. Acc: 0.974. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.051. Acc: 0.975. Test loss: 0.002.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.078. Acc: 0.980. Test loss: 0.006.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.036. Acc: 0.985. Test loss: 0.009.Test acc: 0.942\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.050. Acc: 0.987. Test loss: 0.000.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.027. Acc: 0.987. Test loss: 0.968.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.197. Acc: 0.877. Test loss: 0.170.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.145. Acc: 0.933. Test loss: 0.207.Test acc: 0.928\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.116. Acc: 0.944. Test loss: 0.012.Test acc: 0.946\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.102. Acc: 0.957. Test loss: 0.069.Test acc: 0.942\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.121. Acc: 0.963. Test loss: 0.054.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.060. Acc: 0.969. Test loss: 0.059.Test acc: 0.935\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.057. Acc: 0.973. Test loss: 0.002.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.063. Acc: 0.978. Test loss: 0.073.Test acc: 0.942\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.032. Acc: 0.983. Test loss: 0.010.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.043. Acc: 0.985. Test loss: 0.005.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.238. Acc: 0.870. Test loss: 1.351.Test acc: 0.928\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.130. Acc: 0.938. Test loss: 0.009.Test acc: 0.947\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.130. Acc: 0.954. Test loss: 0.025.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.109. Acc: 0.959. Test loss: 0.001.Test acc: 0.946\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.088. Acc: 0.966. Test loss: 0.016.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.061. Acc: 0.973. Test loss: 0.052.Test acc: 0.935\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.076. Acc: 0.976. Test loss: 0.531.Test acc: 0.940\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.058. Acc: 0.981. Test loss: 0.037.Test acc: 0.936\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.093. Acc: 0.983. Test loss: 1.064.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.015. Acc: 0.984. Test loss: 0.472.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.203. Acc: 0.889. Test loss: 0.081.Test acc: 0.919\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.122. Acc: 0.930. Test loss: 0.172.Test acc: 0.939\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.104. Acc: 0.949. Test loss: 0.076.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.115. Acc: 0.956. Test loss: 0.157.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.098. Acc: 0.966. Test loss: 0.470.Test acc: 0.945\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.101. Acc: 0.968. Test loss: 0.008.Test acc: 0.939\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.085. Acc: 0.968. Test loss: 0.011.Test acc: 0.944\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.071. Acc: 0.973. Test loss: 2.070.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.030. Acc: 0.979. Test loss: 0.016.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.051. Acc: 0.984. Test loss: 0.006.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.196. Acc: 0.937. Test loss: 0.038.Test acc: 0.944\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.146. Acc: 0.953. Test loss: 0.021.Test acc: 0.951\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.102. Acc: 0.963. Test loss: 0.153.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.044. Acc: 0.972. Test loss: 0.005.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.067. Acc: 0.978. Test loss: 0.915.Test acc: 0.946\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.071. Acc: 0.982. Test loss: 0.031.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.030. Acc: 0.987. Test loss: 0.000.Test acc: 0.948\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.032. Acc: 0.987. Test loss: 0.005.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.016. Acc: 0.989. Test loss: 0.009.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.027. Acc: 0.991. Test loss: 0.000.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.212. Acc: 0.917. Test loss: 0.058.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.185. Acc: 0.939. Test loss: 0.146.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.111. Acc: 0.954. Test loss: 0.188.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.097. Acc: 0.962. Test loss: 0.031.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.095. Acc: 0.968. Test loss: 1.115.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.078. Acc: 0.972. Test loss: 0.591.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.072. Acc: 0.972. Test loss: 0.132.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.071. Acc: 0.975. Test loss: 0.025.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.049. Acc: 0.978. Test loss: 0.750.Test acc: 0.950\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.033. Acc: 0.981. Test loss: 0.011.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.223. Acc: 0.938. Test loss: 0.029.Test acc: 0.947\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.131. Acc: 0.955. Test loss: 1.519.Test acc: 0.951\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.101. Acc: 0.965. Test loss: 0.040.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.122. Acc: 0.973. Test loss: 0.029.Test acc: 0.953\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.068. Acc: 0.979. Test loss: 0.035.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.057. Acc: 0.982. Test loss: 0.019.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.034. Acc: 0.985. Test loss: 0.021.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.045. Acc: 0.989. Test loss: 0.002.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.016. Acc: 0.991. Test loss: 0.047.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.023. Acc: 0.992. Test loss: 0.000.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.243. Acc: 0.885. Test loss: 0.035.Test acc: 0.923\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.180. Acc: 0.920. Test loss: 0.024.Test acc: 0.933\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.144. Acc: 0.949. Test loss: 0.019.Test acc: 0.941\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.119. Acc: 0.956. Test loss: 0.765.Test acc: 0.944\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.092. Acc: 0.964. Test loss: 0.700.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.105. Acc: 0.971. Test loss: 1.396.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.035. Acc: 0.977. Test loss: 0.001.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.096. Acc: 0.981. Test loss: 0.013.Test acc: 0.938\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.044. Acc: 0.984. Test loss: 0.006.Test acc: 0.936\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.030. Acc: 0.988. Test loss: 0.001.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.224. Acc: 0.889. Test loss: 0.029.Test acc: 0.929\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.138. Acc: 0.938. Test loss: 0.039.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.103. Acc: 0.953. Test loss: 0.011.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.110. Acc: 0.961. Test loss: 0.021.Test acc: 0.937\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.088. Acc: 0.969. Test loss: 0.003.Test acc: 0.937\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.063. Acc: 0.973. Test loss: 0.431.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.093. Acc: 0.979. Test loss: 0.014.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.071. Acc: 0.982. Test loss: 0.101.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.049. Acc: 0.988. Test loss: 0.000.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.022. Acc: 0.989. Test loss: 0.000.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.170. Acc: 0.896. Test loss: 0.051.Test acc: 0.943\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.129. Acc: 0.950. Test loss: 0.010.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.134. Acc: 0.959. Test loss: 0.163.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.074. Acc: 0.966. Test loss: 0.844.Test acc: 0.940\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.080. Acc: 0.973. Test loss: 0.012.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.053. Acc: 0.980. Test loss: 0.155.Test acc: 0.935\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.058. Acc: 0.982. Test loss: 0.741.Test acc: 0.939\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.023. Acc: 0.986. Test loss: 0.000.Test acc: 0.943\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.020. Acc: 0.989. Test loss: 0.198.Test acc: 0.937\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.040. Acc: 0.992. Test loss: 0.021.Test acc: 0.939\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.149. Acc: 0.913. Test loss: 0.038.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.171. Acc: 0.942. Test loss: 0.138.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.141. Acc: 0.954. Test loss: 0.004.Test acc: 0.953\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.095. Acc: 0.963. Test loss: 0.180.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.064. Acc: 0.969. Test loss: 0.076.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.103. Acc: 0.973. Test loss: 0.001.Test acc: 0.950\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.072. Acc: 0.979. Test loss: 0.476.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.037. Acc: 0.982. Test loss: 0.010.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.049. Acc: 0.985. Test loss: 0.483.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.029. Acc: 0.989. Test loss: 0.001.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.142. Acc: 0.937. Test loss: 0.031.Test acc: 0.943\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.113. Acc: 0.950. Test loss: 0.024.Test acc: 0.950\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.098. Acc: 0.961. Test loss: 0.029.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.080. Acc: 0.968. Test loss: 0.024.Test acc: 0.952\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.061. Acc: 0.974. Test loss: 0.033.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.051. Acc: 0.979. Test loss: 0.008.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.052. Acc: 0.983. Test loss: 0.624.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.031. Acc: 0.987. Test loss: 0.077.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.038. Acc: 0.990. Test loss: 0.000.Test acc: 0.946\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.044. Acc: 0.992. Test loss: 1.307.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.187. Acc: 0.938. Test loss: 0.041.Test acc: 0.942\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.163. Acc: 0.954. Test loss: 0.030.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.106. Acc: 0.964. Test loss: 0.003.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.141. Acc: 0.972. Test loss: 0.010.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.071. Acc: 0.977. Test loss: 0.018.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.076. Acc: 0.980. Test loss: 0.003.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.045. Acc: 0.984. Test loss: 0.000.Test acc: 0.943\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.047. Acc: 0.989. Test loss: 0.169.Test acc: 0.944\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.027. Acc: 0.991. Test loss: 0.105.Test acc: 0.944\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.032. Acc: 0.992. Test loss: 0.001.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.251. Acc: 0.591. Test loss: 0.548.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.199. Acc: 0.936. Test loss: 0.045.Test acc: 0.935\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.194. Acc: 0.942. Test loss: 0.122.Test acc: 0.941\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.142. Acc: 0.948. Test loss: 0.011.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.134. Acc: 0.955. Test loss: 0.475.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.123. Acc: 0.961. Test loss: 0.009.Test acc: 0.942\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.067. Acc: 0.968. Test loss: 0.012.Test acc: 0.943\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.094. Acc: 0.972. Test loss: 0.009.Test acc: 0.936\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.064. Acc: 0.977. Test loss: 0.423.Test acc: 0.940\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.084. Acc: 0.981. Test loss: 0.010.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.198. Acc: 0.547. Test loss: 0.044.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.164. Acc: 0.937. Test loss: 0.057.Test acc: 0.936\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.171. Acc: 0.942. Test loss: 0.659.Test acc: 0.942\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.127. Acc: 0.951. Test loss: 0.184.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.133. Acc: 0.956. Test loss: 0.017.Test acc: 0.943\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.105. Acc: 0.960. Test loss: 0.030.Test acc: 0.944\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.086. Acc: 0.965. Test loss: 0.107.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.109. Acc: 0.969. Test loss: 0.009.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.076. Acc: 0.973. Test loss: 0.009.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.086. Acc: 0.977. Test loss: 0.016.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.234. Acc: 0.567. Test loss: 0.039.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.184. Acc: 0.936. Test loss: 0.222.Test acc: 0.934\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.138. Acc: 0.941. Test loss: 0.475.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.170. Acc: 0.948. Test loss: 0.058.Test acc: 0.942\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.132. Acc: 0.954. Test loss: 0.330.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.101. Acc: 0.960. Test loss: 0.850.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.081. Acc: 0.965. Test loss: 0.092.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.087. Acc: 0.970. Test loss: 0.143.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.062. Acc: 0.974. Test loss: 0.010.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.069. Acc: 0.978. Test loss: 0.011.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.257. Acc: 0.829. Test loss: 0.045.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.186. Acc: 0.934. Test loss: 0.799.Test acc: 0.941\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.175. Acc: 0.947. Test loss: 0.637.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.155. Acc: 0.954. Test loss: 0.047.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.134. Acc: 0.959. Test loss: 0.035.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.137. Acc: 0.964. Test loss: 0.007.Test acc: 0.950\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.128. Acc: 0.967. Test loss: 0.051.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.089. Acc: 0.973. Test loss: 0.335.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.141. Acc: 0.974. Test loss: 0.020.Test acc: 0.952\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.104. Acc: 0.978. Test loss: 0.017.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.269. Acc: 0.930. Test loss: 0.047.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.172. Acc: 0.936. Test loss: 0.080.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.121. Acc: 0.948. Test loss: 0.025.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.131. Acc: 0.956. Test loss: 0.175.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.110. Acc: 0.960. Test loss: 0.119.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.087. Acc: 0.965. Test loss: 0.025.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.090. Acc: 0.968. Test loss: 0.367.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.106. Acc: 0.974. Test loss: 0.029.Test acc: 0.953\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.103. Acc: 0.976. Test loss: 0.048.Test acc: 0.951\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.074. Acc: 0.980. Test loss: 0.003.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.221. Acc: 0.876. Test loss: 0.040.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.191. Acc: 0.937. Test loss: 0.056.Test acc: 0.941\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.155. Acc: 0.947. Test loss: 0.105.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.124. Acc: 0.953. Test loss: 0.246.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.092. Acc: 0.957. Test loss: 0.067.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.108. Acc: 0.962. Test loss: 0.010.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.136. Acc: 0.966. Test loss: 0.028.Test acc: 0.952\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.079. Acc: 0.971. Test loss: 0.038.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.085. Acc: 0.973. Test loss: 0.002.Test acc: 0.952\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.069. Acc: 0.979. Test loss: 0.086.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.216. Acc: 0.660. Test loss: 0.059.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.099. Acc: 0.935. Test loss: 0.036.Test acc: 0.938\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.221. Acc: 0.945. Test loss: 0.020.Test acc: 0.942\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.128. Acc: 0.953. Test loss: 0.011.Test acc: 0.944\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.134. Acc: 0.957. Test loss: 0.309.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.077. Acc: 0.962. Test loss: 0.114.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.089. Acc: 0.966. Test loss: 0.012.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.048. Acc: 0.970. Test loss: 0.178.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.083. Acc: 0.975. Test loss: 0.033.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.056. Acc: 0.981. Test loss: 0.006.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.200. Acc: 0.646. Test loss: 0.072.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.162. Acc: 0.938. Test loss: 0.602.Test acc: 0.940\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.150. Acc: 0.948. Test loss: 0.678.Test acc: 0.945\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.149. Acc: 0.955. Test loss: 0.020.Test acc: 0.943\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.162. Acc: 0.957. Test loss: 0.089.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.087. Acc: 0.963. Test loss: 0.007.Test acc: 0.941\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.097. Acc: 0.965. Test loss: 0.101.Test acc: 0.941\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.056. Acc: 0.971. Test loss: 0.485.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.060. Acc: 0.975. Test loss: 0.008.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.062. Acc: 0.981. Test loss: 0.151.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.247. Acc: 0.660. Test loss: 0.085.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.166. Acc: 0.936. Test loss: 0.745.Test acc: 0.937\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.147. Acc: 0.947. Test loss: 0.012.Test acc: 0.941\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.134. Acc: 0.954. Test loss: 0.020.Test acc: 0.941\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.148. Acc: 0.959. Test loss: 0.191.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.124. Acc: 0.964. Test loss: 0.008.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.077. Acc: 0.969. Test loss: 0.025.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.051. Acc: 0.974. Test loss: 0.056.Test acc: 0.943\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.079. Acc: 0.979. Test loss: 0.001.Test acc: 0.944\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.047. Acc: 0.983. Test loss: 0.002.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.274. Acc: 0.891. Test loss: 1.526.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.233. Acc: 0.939. Test loss: 0.035.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.194. Acc: 0.949. Test loss: 0.084.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.129. Acc: 0.955. Test loss: 0.022.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.123. Acc: 0.960. Test loss: 0.020.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.065. Acc: 0.965. Test loss: 0.561.Test acc: 0.953\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.097. Acc: 0.970. Test loss: 0.033.Test acc: 0.952\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.129. Acc: 0.974. Test loss: 0.012.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.060. Acc: 0.979. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.056. Acc: 0.982. Test loss: 0.308.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.215. Acc: 0.930. Test loss: 0.123.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.162. Acc: 0.940. Test loss: 0.068.Test acc: 0.943\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.130. Acc: 0.952. Test loss: 0.024.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.179. Acc: 0.957. Test loss: 0.009.Test acc: 0.946\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.108. Acc: 0.962. Test loss: 0.088.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.091. Acc: 0.967. Test loss: 0.034.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.057. Acc: 0.971. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.074. Acc: 0.976. Test loss: 0.010.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.044. Acc: 0.978. Test loss: 0.729.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.078. Acc: 0.983. Test loss: 0.002.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.225. Acc: 0.931. Test loss: 0.072.Test acc: 0.933\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.150. Acc: 0.942. Test loss: 0.037.Test acc: 0.943\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.192. Acc: 0.951. Test loss: 0.544.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.193. Acc: 0.957. Test loss: 0.032.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.108. Acc: 0.962. Test loss: 0.048.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.136. Acc: 0.964. Test loss: 0.061.Test acc: 0.950\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.122. Acc: 0.970. Test loss: 0.010.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.113. Acc: 0.973. Test loss: 0.020.Test acc: 0.952\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.084. Acc: 0.978. Test loss: 0.009.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.034. Acc: 0.982. Test loss: 0.012.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.237. Acc: 0.567. Test loss: 0.624.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.149. Acc: 0.942. Test loss: 1.131.Test acc: 0.936\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.093. Acc: 0.946. Test loss: 0.021.Test acc: 0.940\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.164. Acc: 0.956. Test loss: 0.056.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.123. Acc: 0.962. Test loss: 0.078.Test acc: 0.942\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.098. Acc: 0.969. Test loss: 0.014.Test acc: 0.944\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.111. Acc: 0.974. Test loss: 0.049.Test acc: 0.943\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.060. Acc: 0.979. Test loss: 0.190.Test acc: 0.943\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.023. Acc: 0.982. Test loss: 0.007.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.035. Acc: 0.985. Test loss: 0.002.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.146. Acc: 0.588. Test loss: 1.033.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.165. Acc: 0.942. Test loss: 0.017.Test acc: 0.936\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.152. Acc: 0.947. Test loss: 0.586.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.108. Acc: 0.957. Test loss: 0.007.Test acc: 0.943\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.076. Acc: 0.964. Test loss: 0.008.Test acc: 0.945\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.077. Acc: 0.971. Test loss: 0.006.Test acc: 0.946\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.077. Acc: 0.976. Test loss: 0.005.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.071. Acc: 0.979. Test loss: 0.027.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.038. Acc: 0.983. Test loss: 0.807.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.071. Acc: 0.986. Test loss: 0.040.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.229. Acc: 0.568. Test loss: 0.628.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.178. Acc: 0.941. Test loss: 0.718.Test acc: 0.939\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.148. Acc: 0.947. Test loss: 0.018.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.156. Acc: 0.954. Test loss: 0.014.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.070. Acc: 0.961. Test loss: 0.016.Test acc: 0.938\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.110. Acc: 0.968. Test loss: 0.537.Test acc: 0.941\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.075. Acc: 0.973. Test loss: 0.006.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.066. Acc: 0.977. Test loss: 0.008.Test acc: 0.946\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.064. Acc: 0.981. Test loss: 0.927.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.057. Acc: 0.984. Test loss: 0.018.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.183. Acc: 0.873. Test loss: 0.567.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.190. Acc: 0.940. Test loss: 0.050.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.144. Acc: 0.952. Test loss: 0.046.Test acc: 0.946\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.174. Acc: 0.960. Test loss: 0.011.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.077. Acc: 0.967. Test loss: 0.033.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.074. Acc: 0.972. Test loss: 0.068.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.082. Acc: 0.975. Test loss: 0.042.Test acc: 0.952\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.126. Acc: 0.979. Test loss: 0.011.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.038. Acc: 0.983. Test loss: 0.022.Test acc: 0.950\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.082. Acc: 0.986. Test loss: 0.008.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.178. Acc: 0.887. Test loss: 0.042.Test acc: 0.932\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.171. Acc: 0.940. Test loss: 0.248.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.122. Acc: 0.949. Test loss: 0.488.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.126. Acc: 0.957. Test loss: 0.747.Test acc: 0.949\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.144. Acc: 0.963. Test loss: 0.015.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.152. Acc: 0.967. Test loss: 0.028.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.085. Acc: 0.973. Test loss: 0.008.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.070. Acc: 0.977. Test loss: 0.019.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.062. Acc: 0.981. Test loss: 0.043.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.096. Acc: 0.984. Test loss: 0.002.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.191. Acc: 0.930. Test loss: 0.034.Test acc: 0.930\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.118. Acc: 0.938. Test loss: 0.039.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.165. Acc: 0.951. Test loss: 0.050.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.138. Acc: 0.960. Test loss: 0.793.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.133. Acc: 0.965. Test loss: 0.034.Test acc: 0.946\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.085. Acc: 0.971. Test loss: 0.010.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.061. Acc: 0.976. Test loss: 0.009.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.086. Acc: 0.981. Test loss: 0.080.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.058. Acc: 0.982. Test loss: 0.003.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.106. Acc: 0.985. Test loss: 0.014.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.191. Acc: 0.681. Test loss: 0.122.Test acc: 0.942\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.165. Acc: 0.942. Test loss: 0.353.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.162. Acc: 0.952. Test loss: 0.055.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.118. Acc: 0.959. Test loss: 0.544.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.099. Acc: 0.965. Test loss: 0.008.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.078. Acc: 0.973. Test loss: 0.186.Test acc: 0.945\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.072. Acc: 0.978. Test loss: 0.752.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.100. Acc: 0.980. Test loss: 0.001.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.026. Acc: 0.986. Test loss: 0.014.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.084. Acc: 0.985. Test loss: 0.007.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.235. Acc: 0.692. Test loss: 0.180.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.140. Acc: 0.940. Test loss: 0.089.Test acc: 0.940\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.111. Acc: 0.951. Test loss: 0.011.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.159. Acc: 0.958. Test loss: 0.045.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.121. Acc: 0.965. Test loss: 0.046.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.074. Acc: 0.971. Test loss: 0.006.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.083. Acc: 0.975. Test loss: 1.187.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.073. Acc: 0.980. Test loss: 0.146.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.076. Acc: 0.982. Test loss: 0.372.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.046. Acc: 0.985. Test loss: 0.009.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.169. Acc: 0.670. Test loss: 0.058.Test acc: 0.940\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.186. Acc: 0.943. Test loss: 0.027.Test acc: 0.939\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.179. Acc: 0.952. Test loss: 0.014.Test acc: 0.945\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.104. Acc: 0.960. Test loss: 0.219.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.079. Acc: 0.965. Test loss: 0.810.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.114. Acc: 0.970. Test loss: 0.140.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.051. Acc: 0.977. Test loss: 0.008.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.074. Acc: 0.979. Test loss: 0.015.Test acc: 0.938\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.054. Acc: 0.982. Test loss: 0.001.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.018. Acc: 0.986. Test loss: 0.007.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.215. Acc: 0.902. Test loss: 0.917.Test acc: 0.939\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.210. Acc: 0.946. Test loss: 0.049.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.161. Acc: 0.955. Test loss: 0.074.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.080. Acc: 0.962. Test loss: 0.794.Test acc: 0.952\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.093. Acc: 0.966. Test loss: 0.030.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.062. Acc: 0.972. Test loss: 0.004.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.079. Acc: 0.977. Test loss: 0.452.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.060. Acc: 0.981. Test loss: 0.009.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.046. Acc: 0.983. Test loss: 0.018.Test acc: 0.953\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.078. Acc: 0.986. Test loss: 0.011.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.199. Acc: 0.931. Test loss: 0.643.Test acc: 0.940\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.157. Acc: 0.946. Test loss: 0.149.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.143. Acc: 0.954. Test loss: 0.062.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.101. Acc: 0.963. Test loss: 0.022.Test acc: 0.952\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.103. Acc: 0.968. Test loss: 0.010.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.072. Acc: 0.974. Test loss: 0.009.Test acc: 0.950\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.097. Acc: 0.978. Test loss: 0.064.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.070. Acc: 0.982. Test loss: 0.694.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.071. Acc: 0.986. Test loss: 0.001.Test acc: 0.946\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.035. Acc: 0.988. Test loss: 0.007.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.213. Acc: 0.846. Test loss: 0.062.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.174. Acc: 0.943. Test loss: 0.400.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.173. Acc: 0.955. Test loss: 0.056.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.163. Acc: 0.963. Test loss: 0.021.Test acc: 0.952\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.092. Acc: 0.968. Test loss: 0.010.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.131. Acc: 0.971. Test loss: 0.008.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.082. Acc: 0.976. Test loss: 0.493.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.069. Acc: 0.981. Test loss: 0.013.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.030. Acc: 0.985. Test loss: 0.019.Test acc: 0.952\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.059. Acc: 0.986. Test loss: 0.024.Test acc: 0.951\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "for epochs in n_epochs:\n",
        "    for lr in learning_rates:\n",
        "        for embedding_dim in e_dims:\n",
        "            for hidden_dim in h_dims:\n",
        "                for th in ths:\n",
        "                    for dp in dps:\n",
        "                        \n",
        "                        print(f'Hyper params: epochs - {epochs}, learning_rate - {lr}, '\n",
        "                             f'embedding_dim - {embedding_dim}, hidden_dim - {hidden_dim}, '\n",
        "                             f'threshold_level - {th}, drop_prob - {dp}.')\n",
        "                        model = LSTMFixedLen(vocab_size=max_words, \n",
        "                                             embedding_dim=embedding_dim, hidden_dim=hidden_dim, \n",
        "                                             drop_prob=dp, use_last=False)\n",
        "                        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "                        model = model.to(device)\n",
        "                        model.train()\n",
        "                        th = th\n",
        "\n",
        "                        train_loss_history = []\n",
        "                        test_loss_history = []\n",
        "\n",
        "\n",
        "                        for epoch in range(epochs):  \n",
        "                            running_items, running_right = 0.0, 0.0\n",
        "                            for i, data in enumerate(train_loader, 0):\n",
        "                                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                                # обнуляем градиент\n",
        "                                optimizer.zero_grad()\n",
        "                                outputs = model(inputs)\n",
        "\n",
        "                                loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "                                loss.backward()\n",
        "                                optimizer.step()\n",
        "\n",
        "                                # подсчет ошибки на обучении\n",
        "                                loss = loss.item()\n",
        "                                running_items += len(labels)\n",
        "                                # подсчет метрики на обучении\n",
        "                                pred_labels = torch.squeeze((outputs > th).int())\n",
        "                                running_right += (labels == pred_labels).sum()\n",
        "\n",
        "                            # выводим статистику о процессе обучения\n",
        "                            model.eval()\n",
        "\n",
        "                            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                                    f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                                    f'Loss: {loss:.3f}. ' \\\n",
        "                                    f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "                            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "                            train_loss_history.append(loss)\n",
        "\n",
        "                                # выводим статистику на тестовых данных\n",
        "                            test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "                            for j, data in enumerate(val_loader):\n",
        "                                test_labels = data[1].to(device)\n",
        "                                test_outputs = model(data[0].to(device))\n",
        "\n",
        "                                # подсчет ошибки на тесте\n",
        "                                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                                # подсчет метрики на тесте\n",
        "                                test_running_total += len(data[1])\n",
        "                                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                                test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "                            test_loss_history.append(test_loss.item())\n",
        "                            print(f'Test loss: {test_loss:.3f}.' \n",
        "                                  f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "                            model.train()\n",
        "\n",
        "                        print('Training is finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465d4fb6",
      "metadata": {
        "papermill": {
          "duration": 0.096773,
          "end_time": "2022-07-18T23:03:23.521371",
          "exception": false,
          "start_time": "2022-07-18T23:03:23.424598",
          "status": "completed"
        },
        "tags": [],
        "id": "465d4fb6"
      },
      "source": [
        "На основе проведенного анализа можно утверждать, что уменьшение порога отсечения не позволяет добиться улучшения модели, поэтому лучше оставить этот показатель на уровне 0.5. Аналогично не дает сколько либо значимых улучшений увеличиние величины дропаута. Самым эффективными по оказываемому влиянию оказываются уменьшение скорости обучения и изменение размерности слоев."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0e4964",
      "metadata": {
        "papermill": {
          "duration": 0.096171,
          "end_time": "2022-07-18T23:03:23.714841",
          "exception": false,
          "start_time": "2022-07-18T23:03:23.618670",
          "status": "completed"
        },
        "tags": [],
        "id": "5c0e4964"
      },
      "source": [
        "Проведем аналогичный поиск по сетке для модели GRU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d35f9597",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T23:03:23.911265Z",
          "iopub.status.busy": "2022-07-18T23:03:23.910881Z",
          "iopub.status.idle": "2022-07-18T23:03:23.919784Z",
          "shell.execute_reply": "2022-07-18T23:03:23.918742Z"
        },
        "papermill": {
          "duration": 0.109918,
          "end_time": "2022-07-18T23:03:23.922002",
          "exception": false,
          "start_time": "2022-07-18T23:03:23.812084",
          "status": "completed"
        },
        "tags": [],
        "id": "d35f9597"
      },
      "outputs": [],
      "source": [
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, drop_prob=0.1, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=drop_prob)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "#         self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "#         x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "       \n",
        "        if self.use_last:\n",
        "            last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "    \n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85e5daca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T23:03:24.119454Z",
          "iopub.status.busy": "2022-07-18T23:03:24.118922Z",
          "iopub.status.idle": "2022-07-18T23:25:10.020865Z",
          "shell.execute_reply": "2022-07-18T23:25:10.018367Z"
        },
        "papermill": {
          "duration": 1306.003325,
          "end_time": "2022-07-18T23:25:10.023580",
          "exception": false,
          "start_time": "2022-07-18T23:03:24.020255",
          "status": "completed"
        },
        "tags": [],
        "id": "85e5daca",
        "outputId": "dfb3c53d-1eb4-4031-ad68-ad6424270de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.173. Acc: 0.898. Test loss: 0.023.Test acc: 0.940\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.099. Acc: 0.952. Test loss: 0.056.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.077. Acc: 0.963. Test loss: 0.164.Test acc: 0.944\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.090. Acc: 0.972. Test loss: 0.551.Test acc: 0.937\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.048. Acc: 0.979. Test loss: 0.004.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.158. Acc: 0.897. Test loss: 0.052.Test acc: 0.947\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.144. Acc: 0.951. Test loss: 0.020.Test acc: 0.951\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.099. Acc: 0.961. Test loss: 0.592.Test acc: 0.939\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.051. Acc: 0.970. Test loss: 0.612.Test acc: 0.947\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.095. Acc: 0.975. Test loss: 0.948.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.202. Acc: 0.898. Test loss: 0.015.Test acc: 0.951\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.127. Acc: 0.952. Test loss: 0.034.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.082. Acc: 0.960. Test loss: 0.011.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.089. Acc: 0.971. Test loss: 0.001.Test acc: 0.945\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.042. Acc: 0.978. Test loss: 0.008.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.138. Acc: 0.926. Test loss: 0.020.Test acc: 0.946\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.139. Acc: 0.955. Test loss: 0.048.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.077. Acc: 0.963. Test loss: 0.474.Test acc: 0.953\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.089. Acc: 0.970. Test loss: 0.165.Test acc: 0.954\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.084. Acc: 0.978. Test loss: 0.005.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.169. Acc: 0.940. Test loss: 0.160.Test acc: 0.949\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.122. Acc: 0.954. Test loss: 0.010.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.155. Acc: 0.964. Test loss: 0.061.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.110. Acc: 0.971. Test loss: 0.019.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.090. Acc: 0.978. Test loss: 0.009.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.090. Acc: 0.938. Test loss: 0.027.Test acc: 0.947\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.146. Acc: 0.955. Test loss: 0.022.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.198. Acc: 0.964. Test loss: 0.009.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.085. Acc: 0.973. Test loss: 0.016.Test acc: 0.949\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.072. Acc: 0.978. Test loss: 0.250.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.182. Acc: 0.897. Test loss: 0.016.Test acc: 0.945\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.121. Acc: 0.951. Test loss: 0.009.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.107. Acc: 0.962. Test loss: 0.006.Test acc: 0.947\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.070. Acc: 0.972. Test loss: 0.031.Test acc: 0.943\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.065. Acc: 0.981. Test loss: 0.005.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.155. Acc: 0.898. Test loss: 0.746.Test acc: 0.948\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.115. Acc: 0.951. Test loss: 0.032.Test acc: 0.948\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.108. Acc: 0.961. Test loss: 0.002.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.082. Acc: 0.970. Test loss: 0.002.Test acc: 0.944\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.063. Acc: 0.975. Test loss: 0.001.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.179. Acc: 0.898. Test loss: 0.836.Test acc: 0.944\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.207. Acc: 0.951. Test loss: 0.037.Test acc: 0.948\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.084. Acc: 0.961. Test loss: 0.047.Test acc: 0.946\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.120. Acc: 0.970. Test loss: 0.002.Test acc: 0.948\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.049. Acc: 0.977. Test loss: 0.703.Test acc: 0.938\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.154. Acc: 0.926. Test loss: 0.014.Test acc: 0.948\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.145. Acc: 0.957. Test loss: 0.285.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.052. Acc: 0.967. Test loss: 0.235.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.064. Acc: 0.977. Test loss: 0.019.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.055. Acc: 0.982. Test loss: 0.006.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.140. Acc: 0.920. Test loss: 0.020.Test acc: 0.948\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.154. Acc: 0.956. Test loss: 0.028.Test acc: 0.949\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.112. Acc: 0.965. Test loss: 0.818.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.074. Acc: 0.974. Test loss: 0.001.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.076. Acc: 0.980. Test loss: 0.046.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.176. Acc: 0.941. Test loss: 0.033.Test acc: 0.950\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.101. Acc: 0.957. Test loss: 0.137.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.136. Acc: 0.965. Test loss: 0.001.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.060. Acc: 0.975. Test loss: 0.065.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.060. Acc: 0.982. Test loss: 0.001.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.151. Acc: 0.899. Test loss: 0.124.Test acc: 0.946\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.129. Acc: 0.953. Test loss: 0.709.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.108. Acc: 0.963. Test loss: 0.018.Test acc: 0.944\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.052. Acc: 0.972. Test loss: 0.004.Test acc: 0.941\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.043. Acc: 0.978. Test loss: 0.009.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.229. Acc: 0.898. Test loss: 0.037.Test acc: 0.949\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.125. Acc: 0.952. Test loss: 0.014.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.059. Acc: 0.964. Test loss: 0.004.Test acc: 0.946\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.972. Test loss: 0.001.Test acc: 0.936\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.079. Acc: 0.979. Test loss: 0.026.Test acc: 0.935\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.147. Acc: 0.899. Test loss: 0.044.Test acc: 0.943\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.128. Acc: 0.953. Test loss: 0.008.Test acc: 0.951\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.102. Acc: 0.965. Test loss: 0.016.Test acc: 0.947\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.061. Acc: 0.974. Test loss: 0.001.Test acc: 0.942\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.049. Acc: 0.981. Test loss: 0.004.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.162. Acc: 0.923. Test loss: 0.015.Test acc: 0.950\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.109. Acc: 0.958. Test loss: 0.025.Test acc: 0.953\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.066. Acc: 0.969. Test loss: 0.026.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.059. Acc: 0.978. Test loss: 0.001.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.026. Acc: 0.984. Test loss: 0.009.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.191. Acc: 0.926. Test loss: 0.113.Test acc: 0.949\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.139. Acc: 0.958. Test loss: 0.139.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.141. Acc: 0.968. Test loss: 0.742.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.080. Acc: 0.976. Test loss: 0.876.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.029. Acc: 0.981. Test loss: 0.001.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.139. Acc: 0.928. Test loss: 0.026.Test acc: 0.949\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.125. Acc: 0.958. Test loss: 0.041.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.112. Acc: 0.968. Test loss: 0.190.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.976. Test loss: 0.065.Test acc: 0.950\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.048. Acc: 0.981. Test loss: 0.013.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.144. Acc: 0.901. Test loss: 0.011.Test acc: 0.948\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.116. Acc: 0.953. Test loss: 0.007.Test acc: 0.949\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.094. Acc: 0.965. Test loss: 0.022.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.065. Acc: 0.976. Test loss: 0.001.Test acc: 0.943\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.083. Acc: 0.981. Test loss: 0.006.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.165. Acc: 0.901. Test loss: 0.034.Test acc: 0.947\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.116. Acc: 0.953. Test loss: 0.023.Test acc: 0.948\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.091. Acc: 0.965. Test loss: 0.001.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.076. Acc: 0.975. Test loss: 0.028.Test acc: 0.937\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.055. Acc: 0.980. Test loss: 0.001.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.130. Acc: 0.899. Test loss: 0.020.Test acc: 0.943\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.142. Acc: 0.955. Test loss: 0.009.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.074. Acc: 0.966. Test loss: 0.013.Test acc: 0.947\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.078. Acc: 0.975. Test loss: 0.003.Test acc: 0.938\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.034. Acc: 0.980. Test loss: 0.018.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.198. Acc: 0.943. Test loss: 0.076.Test acc: 0.949\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.128. Acc: 0.958. Test loss: 0.356.Test acc: 0.952\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.125. Acc: 0.970. Test loss: 0.069.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.085. Acc: 0.978. Test loss: 0.004.Test acc: 0.949\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.075. Acc: 0.983. Test loss: 0.001.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.188. Acc: 0.931. Test loss: 0.024.Test acc: 0.948\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.165. Acc: 0.958. Test loss: 0.040.Test acc: 0.953\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.074. Acc: 0.968. Test loss: 0.004.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.116. Acc: 0.977. Test loss: 0.664.Test acc: 0.948\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.027. Acc: 0.984. Test loss: 0.002.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.148. Acc: 0.939. Test loss: 0.050.Test acc: 0.949\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.118. Acc: 0.958. Test loss: 1.104.Test acc: 0.953\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.060. Acc: 0.969. Test loss: 0.007.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.072. Acc: 0.977. Test loss: 0.017.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.061. Acc: 0.983. Test loss: 0.363.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.269. Acc: 0.676. Test loss: 0.557.Test acc: 0.933\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.113. Acc: 0.938. Test loss: 0.071.Test acc: 0.939\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.144. Acc: 0.945. Test loss: 0.031.Test acc: 0.940\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.138. Acc: 0.951. Test loss: 0.053.Test acc: 0.944\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.063. Acc: 0.955. Test loss: 0.105.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.290. Acc: 0.641. Test loss: 0.047.Test acc: 0.934\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.200. Acc: 0.938. Test loss: 0.594.Test acc: 0.936\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.196. Acc: 0.946. Test loss: 0.060.Test acc: 0.938\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.176. Acc: 0.949. Test loss: 0.155.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.078. Acc: 0.955. Test loss: 0.849.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.249. Acc: 0.664. Test loss: 0.052.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.196. Acc: 0.939. Test loss: 0.025.Test acc: 0.936\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.078. Acc: 0.943. Test loss: 0.107.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.140. Acc: 0.951. Test loss: 0.095.Test acc: 0.944\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.179. Acc: 0.956. Test loss: 0.050.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.264. Acc: 0.886. Test loss: 0.039.Test acc: 0.933\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.192. Acc: 0.940. Test loss: 0.028.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.170. Acc: 0.947. Test loss: 0.108.Test acc: 0.948\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.146. Acc: 0.954. Test loss: 0.094.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.099. Acc: 0.958. Test loss: 0.009.Test acc: 0.953\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.251. Acc: 0.906. Test loss: 1.182.Test acc: 0.932\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.192. Acc: 0.939. Test loss: 0.075.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.159. Acc: 0.950. Test loss: 0.042.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.160. Acc: 0.957. Test loss: 0.059.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.142. Acc: 0.960. Test loss: 0.015.Test acc: 0.953\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.225. Acc: 0.930. Test loss: 0.070.Test acc: 0.934\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.147. Acc: 0.941. Test loss: 0.139.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.141. Acc: 0.950. Test loss: 0.202.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.139. Acc: 0.957. Test loss: 0.046.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.127. Acc: 0.961. Test loss: 0.008.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.215. Acc: 0.751. Test loss: 0.090.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.182. Acc: 0.938. Test loss: 0.023.Test acc: 0.942\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.137. Acc: 0.947. Test loss: 0.688.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.124. Acc: 0.952. Test loss: 0.320.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.153. Acc: 0.957. Test loss: 0.011.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.195. Acc: 0.767. Test loss: 0.081.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.146. Acc: 0.940. Test loss: 0.440.Test acc: 0.941\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.121. Acc: 0.945. Test loss: 0.012.Test acc: 0.947\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.126. Acc: 0.951. Test loss: 0.048.Test acc: 0.945\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.081. Acc: 0.955. Test loss: 0.012.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.213. Acc: 0.747. Test loss: 0.060.Test acc: 0.935\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.153. Acc: 0.938. Test loss: 0.016.Test acc: 0.941\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.157. Acc: 0.947. Test loss: 0.049.Test acc: 0.944\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.123. Acc: 0.951. Test loss: 0.015.Test acc: 0.948\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.094. Acc: 0.957. Test loss: 0.018.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.151. Acc: 0.890. Test loss: 0.143.Test acc: 0.935\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.124. Acc: 0.943. Test loss: 0.027.Test acc: 0.945\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.106. Acc: 0.952. Test loss: 0.014.Test acc: 0.948\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.109. Acc: 0.958. Test loss: 0.014.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.073. Acc: 0.961. Test loss: 0.014.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.192. Acc: 0.932. Test loss: 0.059.Test acc: 0.937\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.152. Acc: 0.945. Test loss: 0.030.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.160. Acc: 0.951. Test loss: 0.014.Test acc: 0.949\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.099. Acc: 0.958. Test loss: 0.043.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.108. Acc: 0.961. Test loss: 0.127.Test acc: 0.953\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.164. Acc: 0.903. Test loss: 0.092.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.190. Acc: 0.941. Test loss: 0.066.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.125. Acc: 0.950. Test loss: 0.029.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.128. Acc: 0.956. Test loss: 0.021.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.172. Acc: 0.960. Test loss: 0.023.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.210. Acc: 0.668. Test loss: 0.059.Test acc: 0.936\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.151. Acc: 0.944. Test loss: 0.021.Test acc: 0.943\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.112. Acc: 0.950. Test loss: 0.012.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.104. Acc: 0.956. Test loss: 0.067.Test acc: 0.948\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.088. Acc: 0.962. Test loss: 0.007.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.240. Acc: 0.740. Test loss: 0.052.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.114. Acc: 0.941. Test loss: 0.152.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.118. Acc: 0.952. Test loss: 0.195.Test acc: 0.945\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.100. Acc: 0.959. Test loss: 0.633.Test acc: 0.946\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.088. Acc: 0.964. Test loss: 0.020.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.200. Acc: 0.653. Test loss: 0.061.Test acc: 0.939\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.188. Acc: 0.941. Test loss: 0.019.Test acc: 0.944\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.086. Acc: 0.949. Test loss: 0.072.Test acc: 0.946\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.124. Acc: 0.957. Test loss: 0.014.Test acc: 0.945\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.079. Acc: 0.961. Test loss: 0.476.Test acc: 0.940\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.174. Acc: 0.928. Test loss: 0.059.Test acc: 0.937\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.145. Acc: 0.945. Test loss: 0.342.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.134. Acc: 0.955. Test loss: 0.012.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.146. Acc: 0.962. Test loss: 0.073.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.071. Acc: 0.967. Test loss: 0.009.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.184. Acc: 0.912. Test loss: 0.054.Test acc: 0.937\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.140. Acc: 0.945. Test loss: 0.020.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.116. Acc: 0.956. Test loss: 0.020.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.132. Acc: 0.961. Test loss: 0.024.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.111. Acc: 0.965. Test loss: 0.149.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.213. Acc: 0.931. Test loss: 0.477.Test acc: 0.937\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.135. Acc: 0.945. Test loss: 0.018.Test acc: 0.947\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.113. Acc: 0.956. Test loss: 0.022.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.132. Acc: 0.962. Test loss: 0.075.Test acc: 0.951\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.101. Acc: 0.967. Test loss: 0.034.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.167. Acc: 0.698. Test loss: 0.130.Test acc: 0.940\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.166. Acc: 0.946. Test loss: 0.045.Test acc: 0.941\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.150. Acc: 0.954. Test loss: 0.054.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.114. Acc: 0.959. Test loss: 0.069.Test acc: 0.942\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.144. Acc: 0.965. Test loss: 0.032.Test acc: 0.940\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.180. Acc: 0.718. Test loss: 0.079.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.121. Acc: 0.945. Test loss: 0.148.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.207. Acc: 0.952. Test loss: 0.063.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.117. Acc: 0.958. Test loss: 0.045.Test acc: 0.938\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.116. Acc: 0.963. Test loss: 0.530.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.155. Acc: 0.730. Test loss: 0.561.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.173. Acc: 0.945. Test loss: 0.080.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.152. Acc: 0.952. Test loss: 0.148.Test acc: 0.943\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.124. Acc: 0.957. Test loss: 0.746.Test acc: 0.947\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.125. Acc: 0.964. Test loss: 1.007.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.216. Acc: 0.932. Test loss: 0.653.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.154. Acc: 0.949. Test loss: 0.057.Test acc: 0.949\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.096. Acc: 0.957. Test loss: 0.058.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.116. Acc: 0.963. Test loss: 0.004.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.122. Acc: 0.967. Test loss: 0.937.Test acc: 0.954\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.165. Acc: 0.932. Test loss: 0.493.Test acc: 0.942\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.159. Acc: 0.950. Test loss: 0.017.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.120. Acc: 0.957. Test loss: 0.016.Test acc: 0.951\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.158. Acc: 0.962. Test loss: 0.048.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.104. Acc: 0.966. Test loss: 0.060.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [44/44]. Loss: 0.180. Acc: 0.929. Test loss: 0.049.Test acc: 0.941\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.158. Acc: 0.948. Test loss: 0.069.Test acc: 0.950\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.145. Acc: 0.957. Test loss: 0.011.Test acc: 0.950\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.132. Acc: 0.962. Test loss: 0.385.Test acc: 0.953\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.088. Acc: 0.966. Test loss: 0.002.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.163. Acc: 0.898. Test loss: 0.023.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.141. Acc: 0.950. Test loss: 0.534.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.111. Acc: 0.958. Test loss: 0.011.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.077. Acc: 0.966. Test loss: 0.223.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.065. Acc: 0.975. Test loss: 0.280.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.059. Acc: 0.980. Test loss: 0.003.Test acc: 0.941\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.060. Acc: 0.985. Test loss: 0.759.Test acc: 0.936\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.060. Acc: 0.988. Test loss: 0.155.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.048. Acc: 0.991. Test loss: 0.026.Test acc: 0.941\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.022. Acc: 0.991. Test loss: 0.902.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.161. Acc: 0.898. Test loss: 0.029.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.113. Acc: 0.951. Test loss: 0.005.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.115. Acc: 0.960. Test loss: 0.192.Test acc: 0.937\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.088. Acc: 0.971. Test loss: 0.050.Test acc: 0.933\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.060. Acc: 0.978. Test loss: 0.077.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.027. Acc: 0.985. Test loss: 0.016.Test acc: 0.945\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.042. Acc: 0.988. Test loss: 0.011.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.032. Acc: 0.989. Test loss: 0.002.Test acc: 0.944\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.067. Acc: 0.990. Test loss: 0.001.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.019. Acc: 0.991. Test loss: 0.171.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.143. Acc: 0.887. Test loss: 0.028.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.113. Acc: 0.950. Test loss: 0.025.Test acc: 0.949\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.086. Acc: 0.960. Test loss: 0.012.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.089. Acc: 0.969. Test loss: 0.033.Test acc: 0.944\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.068. Acc: 0.977. Test loss: 0.088.Test acc: 0.935\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.061. Acc: 0.980. Test loss: 0.005.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.046. Acc: 0.987. Test loss: 0.000.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.021. Acc: 0.990. Test loss: 0.000.Test acc: 0.933\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.036. Acc: 0.990. Test loss: 0.012.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.024. Acc: 0.990. Test loss: 0.001.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.180. Acc: 0.936. Test loss: 0.131.Test acc: 0.948\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.149. Acc: 0.954. Test loss: 0.082.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.101. Acc: 0.963. Test loss: 0.005.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.065. Acc: 0.971. Test loss: 0.014.Test acc: 0.953\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.084. Acc: 0.976. Test loss: 0.532.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.043. Acc: 0.982. Test loss: 0.002.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.046. Acc: 0.986. Test loss: 0.007.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.040. Acc: 0.989. Test loss: 0.926.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.036. Acc: 0.989. Test loss: 0.002.Test acc: 0.945\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.033. Acc: 0.992. Test loss: 0.001.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.109. Acc: 0.920. Test loss: 0.037.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.133. Acc: 0.955. Test loss: 0.011.Test acc: 0.950\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.117. Acc: 0.963. Test loss: 0.006.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.132. Acc: 0.970. Test loss: 0.162.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.055. Acc: 0.975. Test loss: 0.014.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.080. Acc: 0.982. Test loss: 0.018.Test acc: 0.946\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.027. Acc: 0.987. Test loss: 0.020.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.023. Acc: 0.990. Test loss: 0.029.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.034. Acc: 0.992. Test loss: 0.010.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.024. Acc: 0.992. Test loss: 1.198.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.177. Acc: 0.939. Test loss: 0.050.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.138. Acc: 0.957. Test loss: 0.216.Test acc: 0.953\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.057. Acc: 0.965. Test loss: 0.079.Test acc: 0.954\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.086. Acc: 0.974. Test loss: 0.413.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.077. Acc: 0.979. Test loss: 1.279.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.072. Acc: 0.986. Test loss: 0.000.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.038. Acc: 0.988. Test loss: 0.022.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.045. Acc: 0.991. Test loss: 0.002.Test acc: 0.946\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.039. Acc: 0.992. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.020. Acc: 0.993. Test loss: 0.344.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.126. Acc: 0.897. Test loss: 0.040.Test acc: 0.943\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.174. Acc: 0.950. Test loss: 0.017.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.163. Acc: 0.963. Test loss: 0.005.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.093. Acc: 0.971. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.040. Acc: 0.981. Test loss: 0.027.Test acc: 0.942\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.038. Acc: 0.985. Test loss: 0.293.Test acc: 0.939\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.085. Acc: 0.986. Test loss: 0.000.Test acc: 0.938\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.035. Acc: 0.989. Test loss: 1.192.Test acc: 0.943\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.027. Acc: 0.992. Test loss: 0.000.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.020. Acc: 0.994. Test loss: 0.000.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.162. Acc: 0.898. Test loss: 0.024.Test acc: 0.948\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.141. Acc: 0.952. Test loss: 0.029.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.085. Acc: 0.961. Test loss: 0.075.Test acc: 0.940\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.094. Acc: 0.973. Test loss: 0.476.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.052. Acc: 0.980. Test loss: 0.001.Test acc: 0.942\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.082. Acc: 0.985. Test loss: 0.002.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.024. Acc: 0.989. Test loss: 0.000.Test acc: 0.939\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.031. Acc: 0.991. Test loss: 1.498.Test acc: 0.944\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.017. Acc: 0.991. Test loss: 0.115.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.024. Acc: 0.992. Test loss: 0.069.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.133. Acc: 0.897. Test loss: 0.067.Test acc: 0.945\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.146. Acc: 0.952. Test loss: 0.012.Test acc: 0.943\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.093. Acc: 0.960. Test loss: 0.016.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.077. Acc: 0.969. Test loss: 0.598.Test acc: 0.943\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.061. Acc: 0.976. Test loss: 0.001.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.044. Acc: 0.984. Test loss: 0.084.Test acc: 0.934\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.048. Acc: 0.986. Test loss: 0.123.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.037. Acc: 0.988. Test loss: 0.203.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.033. Acc: 0.990. Test loss: 0.004.Test acc: 0.935\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.015. Acc: 0.992. Test loss: 0.000.Test acc: 0.951\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.184. Acc: 0.937. Test loss: 0.790.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.095. Acc: 0.955. Test loss: 0.017.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.067. Acc: 0.965. Test loss: 0.006.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.074. Acc: 0.973. Test loss: 0.561.Test acc: 0.952\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.055. Acc: 0.980. Test loss: 1.477.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.065. Acc: 0.987. Test loss: 0.207.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.041. Acc: 0.991. Test loss: 0.019.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.039. Acc: 0.992. Test loss: 0.012.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.034. Acc: 0.991. Test loss: 0.098.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.045. Acc: 0.991. Test loss: 0.126.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.108. Acc: 0.941. Test loss: 0.024.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.112. Acc: 0.956. Test loss: 0.068.Test acc: 0.951\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.090. Acc: 0.966. Test loss: 0.015.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.091. Acc: 0.973. Test loss: 0.008.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.068. Acc: 0.983. Test loss: 1.796.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.078. Acc: 0.988. Test loss: 0.000.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.034. Acc: 0.989. Test loss: 0.550.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.016. Acc: 0.991. Test loss: 0.127.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.043. Acc: 0.992. Test loss: 0.000.Test acc: 0.952\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.025. Acc: 0.992. Test loss: 0.015.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.129. Acc: 0.920. Test loss: 0.023.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.159. Acc: 0.955. Test loss: 0.009.Test acc: 0.950\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.101. Acc: 0.965. Test loss: 0.028.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.056. Acc: 0.973. Test loss: 0.585.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.049. Acc: 0.982. Test loss: 1.096.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.027. Acc: 0.984. Test loss: 0.002.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.055. Acc: 0.987. Test loss: 0.532.Test acc: 0.944\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.017. Acc: 0.990. Test loss: 0.002.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.016. Acc: 0.992. Test loss: 1.667.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.028. Acc: 0.993. Test loss: 0.043.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.198. Acc: 0.898. Test loss: 0.021.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.120. Acc: 0.954. Test loss: 0.041.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.076. Acc: 0.965. Test loss: 0.016.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.117. Acc: 0.975. Test loss: 0.057.Test acc: 0.946\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.055. Acc: 0.981. Test loss: 0.047.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.013. Acc: 0.985. Test loss: 0.002.Test acc: 0.943\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.034. Acc: 0.987. Test loss: 0.000.Test acc: 0.939\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.018. Acc: 0.990. Test loss: 0.000.Test acc: 0.942\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.024. Acc: 0.991. Test loss: 0.809.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.046. Acc: 0.993. Test loss: 0.000.Test acc: 0.936\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.233. Acc: 0.898. Test loss: 0.026.Test acc: 0.946\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.110. Acc: 0.954. Test loss: 0.138.Test acc: 0.949\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.122. Acc: 0.965. Test loss: 0.003.Test acc: 0.945\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.119. Acc: 0.975. Test loss: 0.030.Test acc: 0.940\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.068. Acc: 0.980. Test loss: 0.017.Test acc: 0.939\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.036. Acc: 0.985. Test loss: 0.084.Test acc: 0.939\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.041. Acc: 0.986. Test loss: 0.000.Test acc: 0.943\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.047. Acc: 0.988. Test loss: 0.001.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.021. Acc: 0.990. Test loss: 0.001.Test acc: 0.937\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.009. Acc: 0.990. Test loss: 2.125.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.185. Acc: 0.900. Test loss: 0.211.Test acc: 0.948\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.135. Acc: 0.956. Test loss: 0.013.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.055. Acc: 0.966. Test loss: 0.010.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.111. Acc: 0.974. Test loss: 0.031.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.052. Acc: 0.980. Test loss: 0.035.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.057. Acc: 0.987. Test loss: 1.385.Test acc: 0.943\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.029. Acc: 0.989. Test loss: 0.002.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.043. Acc: 0.989. Test loss: 0.000.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.025. Acc: 0.991. Test loss: 0.016.Test acc: 0.937\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.015. Acc: 0.993. Test loss: 0.000.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.142. Acc: 0.939. Test loss: 0.042.Test acc: 0.948\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.138. Acc: 0.956. Test loss: 0.023.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.083. Acc: 0.967. Test loss: 0.060.Test acc: 0.953\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.074. Acc: 0.975. Test loss: 0.092.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.054. Acc: 0.979. Test loss: 0.010.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.060. Acc: 0.984. Test loss: 0.003.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.057. Acc: 0.988. Test loss: 0.000.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.039. Acc: 0.991. Test loss: 0.000.Test acc: 0.946\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.032. Acc: 0.992. Test loss: 0.686.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.025. Acc: 0.993. Test loss: 0.000.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.176. Acc: 0.939. Test loss: 0.179.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.151. Acc: 0.957. Test loss: 0.021.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.147. Acc: 0.968. Test loss: 0.061.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.070. Acc: 0.975. Test loss: 0.001.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.054. Acc: 0.981. Test loss: 0.147.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.050. Acc: 0.985. Test loss: 0.016.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.028. Acc: 0.989. Test loss: 0.488.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.032. Acc: 0.991. Test loss: 0.037.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.021. Acc: 0.991. Test loss: 0.007.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.045. Acc: 0.991. Test loss: 0.019.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.145. Acc: 0.941. Test loss: 0.492.Test acc: 0.948\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.114. Acc: 0.958. Test loss: 0.020.Test acc: 0.953\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.099. Acc: 0.969. Test loss: 0.550.Test acc: 0.952\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.087. Acc: 0.976. Test loss: 0.040.Test acc: 0.952\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.049. Acc: 0.983. Test loss: 0.000.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.067. Acc: 0.985. Test loss: 0.005.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.037. Acc: 0.986. Test loss: 0.102.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.049. Acc: 0.990. Test loss: 0.001.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.016. Acc: 0.992. Test loss: 0.266.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.006. Acc: 0.993. Test loss: 0.000.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.132. Acc: 0.898. Test loss: 0.026.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.098. Acc: 0.954. Test loss: 0.337.Test acc: 0.939\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.086. Acc: 0.966. Test loss: 0.006.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.062. Acc: 0.976. Test loss: 0.001.Test acc: 0.940\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.076. Acc: 0.983. Test loss: 0.001.Test acc: 0.940\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.054. Acc: 0.987. Test loss: 0.000.Test acc: 0.943\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.050. Acc: 0.989. Test loss: 0.000.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.021. Acc: 0.989. Test loss: 0.000.Test acc: 0.943\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.019. Acc: 0.992. Test loss: 0.000.Test acc: 0.941\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.012. Acc: 0.992. Test loss: 0.000.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.178. Acc: 0.900. Test loss: 0.054.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.119. Acc: 0.954. Test loss: 0.007.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.099. Acc: 0.965. Test loss: 0.055.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.077. Acc: 0.975. Test loss: 0.020.Test acc: 0.943\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.057. Acc: 0.983. Test loss: 0.517.Test acc: 0.936\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.030. Acc: 0.986. Test loss: 0.076.Test acc: 0.942\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.014. Acc: 0.990. Test loss: 0.013.Test acc: 0.944\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.040. Acc: 0.991. Test loss: 0.121.Test acc: 0.942\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.033. Acc: 0.988. Test loss: 0.543.Test acc: 0.938\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.057. Acc: 0.989. Test loss: 1.588.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.157. Acc: 0.899. Test loss: 0.393.Test acc: 0.942\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.122. Acc: 0.954. Test loss: 0.004.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.087. Acc: 0.964. Test loss: 0.001.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.110. Acc: 0.974. Test loss: 0.192.Test acc: 0.942\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.048. Acc: 0.982. Test loss: 0.179.Test acc: 0.941\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.029. Acc: 0.986. Test loss: 0.000.Test acc: 0.942\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.042. Acc: 0.989. Test loss: 0.000.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.036. Acc: 0.990. Test loss: 0.000.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.039. Acc: 0.990. Test loss: 1.702.Test acc: 0.942\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.014. Acc: 0.990. Test loss: 0.000.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.228. Acc: 0.933. Test loss: 0.030.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.111. Acc: 0.959. Test loss: 0.069.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.070. Acc: 0.967. Test loss: 0.004.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.060. Acc: 0.976. Test loss: 0.001.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.066. Acc: 0.984. Test loss: 0.000.Test acc: 0.947\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.041. Acc: 0.987. Test loss: 0.002.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.027. Acc: 0.990. Test loss: 0.005.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.040. Acc: 0.992. Test loss: 0.444.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.021. Acc: 0.991. Test loss: 0.015.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.039. Acc: 0.991. Test loss: 0.027.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.128. Acc: 0.930. Test loss: 0.044.Test acc: 0.949\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.122. Acc: 0.958. Test loss: 0.011.Test acc: 0.953\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.093. Acc: 0.968. Test loss: 0.287.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.054. Acc: 0.977. Test loss: 0.000.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.056. Acc: 0.981. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.062. Acc: 0.986. Test loss: 0.007.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.039. Acc: 0.989. Test loss: 0.001.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.011. Acc: 0.991. Test loss: 0.011.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.015. Acc: 0.993. Test loss: 0.019.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.020. Acc: 0.994. Test loss: 0.528.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.090. Acc: 0.930. Test loss: 0.716.Test acc: 0.950\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.109. Acc: 0.959. Test loss: 0.366.Test acc: 0.952\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.067. Acc: 0.970. Test loss: 0.003.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.090. Acc: 0.979. Test loss: 0.064.Test acc: 0.944\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.051. Acc: 0.984. Test loss: 0.011.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.038. Acc: 0.986. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.040. Acc: 0.989. Test loss: 0.000.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.020. Acc: 0.992. Test loss: 0.008.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.019. Acc: 0.992. Test loss: 0.002.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.025. Acc: 0.993. Test loss: 0.000.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.254. Acc: 0.641. Test loss: 0.047.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.172. Acc: 0.939. Test loss: 0.051.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.156. Acc: 0.947. Test loss: 0.021.Test acc: 0.942\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.160. Acc: 0.953. Test loss: 0.905.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.170. Acc: 0.959. Test loss: 0.488.Test acc: 0.942\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.101. Acc: 0.961. Test loss: 0.065.Test acc: 0.946\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.144. Acc: 0.965. Test loss: 1.157.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.086. Acc: 0.968. Test loss: 0.010.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.097. Acc: 0.972. Test loss: 0.240.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.116. Acc: 0.976. Test loss: 0.195.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.244. Acc: 0.644. Test loss: 0.048.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.237. Acc: 0.937. Test loss: 0.622.Test acc: 0.941\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.171. Acc: 0.945. Test loss: 0.020.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.116. Acc: 0.950. Test loss: 0.094.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.090. Acc: 0.956. Test loss: 0.025.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.134. Acc: 0.959. Test loss: 0.023.Test acc: 0.947\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.103. Acc: 0.964. Test loss: 0.114.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.074. Acc: 0.969. Test loss: 0.281.Test acc: 0.942\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.068. Acc: 0.972. Test loss: 0.192.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.054. Acc: 0.976. Test loss: 0.015.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.146. Acc: 0.659. Test loss: 0.046.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.229. Acc: 0.938. Test loss: 0.414.Test acc: 0.941\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.161. Acc: 0.945. Test loss: 0.029.Test acc: 0.938\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.116. Acc: 0.951. Test loss: 0.009.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.098. Acc: 0.954. Test loss: 0.026.Test acc: 0.946\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.106. Acc: 0.960. Test loss: 0.020.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.064. Acc: 0.964. Test loss: 0.150.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.058. Acc: 0.968. Test loss: 0.809.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.109. Acc: 0.972. Test loss: 0.013.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.090. Acc: 0.977. Test loss: 0.022.Test acc: 0.932\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.219. Acc: 0.930. Test loss: 0.692.Test acc: 0.933\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.177. Acc: 0.938. Test loss: 0.041.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.114. Acc: 0.951. Test loss: 0.014.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.114. Acc: 0.957. Test loss: 0.028.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.081. Acc: 0.961. Test loss: 0.221.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.091. Acc: 0.965. Test loss: 0.010.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.097. Acc: 0.968. Test loss: 0.019.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.099. Acc: 0.972. Test loss: 0.020.Test acc: 0.946\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.085. Acc: 0.977. Test loss: 0.805.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.051. Acc: 0.981. Test loss: 0.004.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.181. Acc: 0.930. Test loss: 0.058.Test acc: 0.933\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.173. Acc: 0.940. Test loss: 0.034.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.152. Acc: 0.950. Test loss: 0.043.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.175. Acc: 0.955. Test loss: 0.025.Test acc: 0.949\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.115. Acc: 0.959. Test loss: 0.083.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.091. Acc: 0.963. Test loss: 0.045.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.153. Acc: 0.966. Test loss: 0.034.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.078. Acc: 0.971. Test loss: 0.040.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.077. Acc: 0.975. Test loss: 0.003.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.093. Acc: 0.979. Test loss: 0.004.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.180. Acc: 0.930. Test loss: 0.059.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.171. Acc: 0.941. Test loss: 0.021.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.136. Acc: 0.950. Test loss: 0.027.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.155. Acc: 0.956. Test loss: 0.554.Test acc: 0.950\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.159. Acc: 0.961. Test loss: 0.031.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.102. Acc: 0.964. Test loss: 0.011.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.121. Acc: 0.969. Test loss: 0.012.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.122. Acc: 0.972. Test loss: 0.209.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.070. Acc: 0.975. Test loss: 0.796.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.060. Acc: 0.980. Test loss: 0.011.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.222. Acc: 0.728. Test loss: 0.602.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.138. Acc: 0.941. Test loss: 0.044.Test acc: 0.941\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.177. Acc: 0.947. Test loss: 0.062.Test acc: 0.944\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.084. Acc: 0.952. Test loss: 0.068.Test acc: 0.941\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.155. Acc: 0.954. Test loss: 0.122.Test acc: 0.934\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.131. Acc: 0.960. Test loss: 0.010.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.071. Acc: 0.963. Test loss: 0.360.Test acc: 0.943\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.064. Acc: 0.970. Test loss: 0.002.Test acc: 0.946\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.063. Acc: 0.974. Test loss: 0.003.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.058. Acc: 0.978. Test loss: 0.004.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.229. Acc: 0.729. Test loss: 0.063.Test acc: 0.938\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.134. Acc: 0.941. Test loss: 0.030.Test acc: 0.941\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.157. Acc: 0.948. Test loss: 0.013.Test acc: 0.946\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.125. Acc: 0.954. Test loss: 0.234.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.110. Acc: 0.956. Test loss: 0.901.Test acc: 0.933\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.093. Acc: 0.961. Test loss: 0.156.Test acc: 0.937\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.108. Acc: 0.966. Test loss: 0.060.Test acc: 0.945\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.060. Acc: 0.972. Test loss: 0.508.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.091. Acc: 0.975. Test loss: 0.002.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.056. Acc: 0.980. Test loss: 0.017.Test acc: 0.938\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.246. Acc: 0.723. Test loss: 0.052.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.154. Acc: 0.939. Test loss: 0.059.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.171. Acc: 0.947. Test loss: 0.064.Test acc: 0.941\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.157. Acc: 0.950. Test loss: 0.075.Test acc: 0.947\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.154. Acc: 0.956. Test loss: 0.007.Test acc: 0.948\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.116. Acc: 0.960. Test loss: 0.226.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.066. Acc: 0.965. Test loss: 0.012.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.079. Acc: 0.969. Test loss: 0.285.Test acc: 0.934\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.041. Acc: 0.974. Test loss: 0.368.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.088. Acc: 0.979. Test loss: 0.008.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.206. Acc: 0.929. Test loss: 0.062.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.187. Acc: 0.942. Test loss: 0.059.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.138. Acc: 0.952. Test loss: 0.439.Test acc: 0.948\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.129. Acc: 0.955. Test loss: 0.037.Test acc: 0.949\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.125. Acc: 0.960. Test loss: 0.527.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.089. Acc: 0.964. Test loss: 0.013.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.085. Acc: 0.969. Test loss: 0.010.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.135. Acc: 0.973. Test loss: 0.002.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.061. Acc: 0.978. Test loss: 0.027.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.044. Acc: 0.983. Test loss: 0.007.Test acc: 0.952\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.168. Acc: 0.925. Test loss: 0.049.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.152. Acc: 0.943. Test loss: 0.046.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.144. Acc: 0.950. Test loss: 0.033.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.144. Acc: 0.956. Test loss: 0.036.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.133. Acc: 0.960. Test loss: 0.008.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.110. Acc: 0.964. Test loss: 0.032.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.111. Acc: 0.968. Test loss: 0.004.Test acc: 0.950\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.035. Acc: 0.972. Test loss: 0.002.Test acc: 0.951\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.125. Acc: 0.977. Test loss: 0.004.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.077. Acc: 0.982. Test loss: 0.008.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.216. Acc: 0.878. Test loss: 0.056.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.163. Acc: 0.944. Test loss: 0.128.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.180. Acc: 0.952. Test loss: 0.025.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.086. Acc: 0.957. Test loss: 0.013.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.141. Acc: 0.962. Test loss: 0.109.Test acc: 0.950\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.103. Acc: 0.964. Test loss: 0.005.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.101. Acc: 0.968. Test loss: 0.074.Test acc: 0.948\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.108. Acc: 0.972. Test loss: 0.016.Test acc: 0.950\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.109. Acc: 0.976. Test loss: 0.021.Test acc: 0.948\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.087. Acc: 0.980. Test loss: 0.002.Test acc: 0.953\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.284. Acc: 0.681. Test loss: 0.046.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.188. Acc: 0.942. Test loss: 0.276.Test acc: 0.939\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.120. Acc: 0.950. Test loss: 0.011.Test acc: 0.946\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.135. Acc: 0.958. Test loss: 0.461.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.114. Acc: 0.962. Test loss: 0.017.Test acc: 0.944\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.100. Acc: 0.969. Test loss: 0.009.Test acc: 0.939\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.091. Acc: 0.973. Test loss: 0.449.Test acc: 0.942\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.061. Acc: 0.980. Test loss: 0.197.Test acc: 0.941\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.066. Acc: 0.985. Test loss: 0.004.Test acc: 0.944\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.035. Acc: 0.987. Test loss: 0.005.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.161. Acc: 0.664. Test loss: 0.040.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.140. Acc: 0.944. Test loss: 0.034.Test acc: 0.942\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.153. Acc: 0.952. Test loss: 0.676.Test acc: 0.939\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.111. Acc: 0.958. Test loss: 0.043.Test acc: 0.937\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.102. Acc: 0.962. Test loss: 0.081.Test acc: 0.943\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.101. Acc: 0.968. Test loss: 0.027.Test acc: 0.943\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.108. Acc: 0.974. Test loss: 0.028.Test acc: 0.947\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.045. Acc: 0.980. Test loss: 0.014.Test acc: 0.939\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.036. Acc: 0.983. Test loss: 0.997.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.046. Acc: 0.987. Test loss: 0.016.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.221. Acc: 0.652. Test loss: 0.058.Test acc: 0.939\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.169. Acc: 0.944. Test loss: 0.019.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.099. Acc: 0.950. Test loss: 0.023.Test acc: 0.946\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.105. Acc: 0.957. Test loss: 0.081.Test acc: 0.948\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.134. Acc: 0.961. Test loss: 0.044.Test acc: 0.945\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.101. Acc: 0.969. Test loss: 0.715.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.047. Acc: 0.972. Test loss: 0.002.Test acc: 0.938\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.039. Acc: 0.977. Test loss: 0.666.Test acc: 0.944\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.094. Acc: 0.982. Test loss: 0.076.Test acc: 0.941\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.072. Acc: 0.986. Test loss: 0.016.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.278. Acc: 0.922. Test loss: 0.044.Test acc: 0.935\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.168. Acc: 0.944. Test loss: 0.025.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.145. Acc: 0.954. Test loss: 0.667.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.100. Acc: 0.960. Test loss: 0.141.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.096. Acc: 0.967. Test loss: 0.588.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.075. Acc: 0.971. Test loss: 0.058.Test acc: 0.948\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.117. Acc: 0.975. Test loss: 0.983.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.072. Acc: 0.981. Test loss: 0.003.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.031. Acc: 0.985. Test loss: 0.015.Test acc: 0.950\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.039. Acc: 0.988. Test loss: 0.024.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.214. Acc: 0.863. Test loss: 0.039.Test acc: 0.934\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.123. Acc: 0.943. Test loss: 0.074.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.159. Acc: 0.953. Test loss: 0.021.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.124. Acc: 0.960. Test loss: 0.014.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.101. Acc: 0.965. Test loss: 0.347.Test acc: 0.952\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.123. Acc: 0.971. Test loss: 0.163.Test acc: 0.950\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.073. Acc: 0.976. Test loss: 0.005.Test acc: 0.951\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.055. Acc: 0.980. Test loss: 0.750.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.074. Acc: 0.984. Test loss: 0.417.Test acc: 0.953\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.081. Acc: 0.986. Test loss: 0.037.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.192. Acc: 0.931. Test loss: 0.048.Test acc: 0.936\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.151. Acc: 0.945. Test loss: 0.082.Test acc: 0.948\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.124. Acc: 0.956. Test loss: 0.199.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.132. Acc: 0.961. Test loss: 0.026.Test acc: 0.949\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.099. Acc: 0.966. Test loss: 0.011.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.065. Acc: 0.972. Test loss: 0.388.Test acc: 0.951\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.088. Acc: 0.976. Test loss: 0.059.Test acc: 0.946\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.060. Acc: 0.981. Test loss: 0.007.Test acc: 0.947\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.065. Acc: 0.985. Test loss: 0.006.Test acc: 0.947\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.064. Acc: 0.987. Test loss: 0.006.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.160. Acc: 0.762. Test loss: 0.072.Test acc: 0.939\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.194. Acc: 0.945. Test loss: 0.060.Test acc: 0.946\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.105. Acc: 0.953. Test loss: 0.063.Test acc: 0.943\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.120. Acc: 0.957. Test loss: 0.056.Test acc: 0.946\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.077. Acc: 0.962. Test loss: 0.032.Test acc: 0.945\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.120. Acc: 0.968. Test loss: 0.044.Test acc: 0.941\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.071. Acc: 0.975. Test loss: 1.080.Test acc: 0.944\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.062. Acc: 0.981. Test loss: 0.007.Test acc: 0.944\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.029. Acc: 0.986. Test loss: 0.006.Test acc: 0.946\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.025. Acc: 0.990. Test loss: 0.001.Test acc: 0.946\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.179. Acc: 0.773. Test loss: 1.009.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.121. Acc: 0.944. Test loss: 1.352.Test acc: 0.945\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.157. Acc: 0.952. Test loss: 0.015.Test acc: 0.946\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.145. Acc: 0.958. Test loss: 0.168.Test acc: 0.943\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.078. Acc: 0.964. Test loss: 0.002.Test acc: 0.938\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.069. Acc: 0.970. Test loss: 0.002.Test acc: 0.940\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.045. Acc: 0.976. Test loss: 0.028.Test acc: 0.943\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.049. Acc: 0.981. Test loss: 0.001.Test acc: 0.945\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.072. Acc: 0.986. Test loss: 0.005.Test acc: 0.944\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.015. Acc: 0.988. Test loss: 0.001.Test acc: 0.950\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.194. Acc: 0.722. Test loss: 0.067.Test acc: 0.938\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.173. Acc: 0.944. Test loss: 0.483.Test acc: 0.944\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.153. Acc: 0.952. Test loss: 0.015.Test acc: 0.947\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.135. Acc: 0.959. Test loss: 0.811.Test acc: 0.945\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.107. Acc: 0.963. Test loss: 0.141.Test acc: 0.949\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.104. Acc: 0.968. Test loss: 0.005.Test acc: 0.946\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.084. Acc: 0.973. Test loss: 0.004.Test acc: 0.948\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.080. Acc: 0.981. Test loss: 0.003.Test acc: 0.938\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.085. Acc: 0.984. Test loss: 1.252.Test acc: 0.943\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.052. Acc: 0.986. Test loss: 0.142.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.145. Acc: 0.933. Test loss: 0.082.Test acc: 0.941\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.205. Acc: 0.947. Test loss: 0.038.Test acc: 0.949\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.142. Acc: 0.956. Test loss: 0.007.Test acc: 0.950\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.076. Acc: 0.962. Test loss: 0.254.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.118. Acc: 0.968. Test loss: 0.004.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.079. Acc: 0.972. Test loss: 0.025.Test acc: 0.949\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.065. Acc: 0.977. Test loss: 0.010.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.055. Acc: 0.983. Test loss: 1.263.Test acc: 0.952\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.039. Acc: 0.987. Test loss: 0.011.Test acc: 0.949\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.054. Acc: 0.990. Test loss: 0.222.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.209. Acc: 0.932. Test loss: 0.089.Test acc: 0.943\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.134. Acc: 0.949. Test loss: 0.303.Test acc: 0.949\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.189. Acc: 0.956. Test loss: 0.037.Test acc: 0.949\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.118. Acc: 0.962. Test loss: 0.198.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.090. Acc: 0.967. Test loss: 0.041.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.083. Acc: 0.972. Test loss: 0.797.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.110. Acc: 0.978. Test loss: 0.002.Test acc: 0.948\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.065. Acc: 0.984. Test loss: 0.057.Test acc: 0.948\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.073. Acc: 0.987. Test loss: 0.951.Test acc: 0.950\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.031. Acc: 0.990. Test loss: 0.855.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [44/44]. Loss: 0.171. Acc: 0.906. Test loss: 0.096.Test acc: 0.940\n",
            "Epoch [2/10]. Step [44/44]. Loss: 0.154. Acc: 0.948. Test loss: 0.230.Test acc: 0.950\n",
            "Epoch [3/10]. Step [44/44]. Loss: 0.151. Acc: 0.957. Test loss: 0.087.Test acc: 0.951\n",
            "Epoch [4/10]. Step [44/44]. Loss: 0.136. Acc: 0.962. Test loss: 0.013.Test acc: 0.951\n",
            "Epoch [5/10]. Step [44/44]. Loss: 0.099. Acc: 0.967. Test loss: 0.019.Test acc: 0.951\n",
            "Epoch [6/10]. Step [44/44]. Loss: 0.083. Acc: 0.971. Test loss: 0.029.Test acc: 0.952\n",
            "Epoch [7/10]. Step [44/44]. Loss: 0.059. Acc: 0.977. Test loss: 0.333.Test acc: 0.949\n",
            "Epoch [8/10]. Step [44/44]. Loss: 0.049. Acc: 0.982. Test loss: 0.002.Test acc: 0.949\n",
            "Epoch [9/10]. Step [44/44]. Loss: 0.040. Acc: 0.987. Test loss: 0.002.Test acc: 0.946\n",
            "Epoch [10/10]. Step [44/44]. Loss: 0.011. Acc: 0.989. Test loss: 0.034.Test acc: 0.950\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "for epochs in n_epochs:\n",
        "    for lr in learning_rates:\n",
        "        for embedding_dim in e_dims:\n",
        "            for hidden_dim in h_dims:\n",
        "                for th in ths:\n",
        "                    for dp in dps:\n",
        "                        \n",
        "                        print(f'Hyper params: epochs - {epochs}, learning_rate - {lr}, '\n",
        "                             f'embedding_dim - {embedding_dim}, hidden_dim - {hidden_dim}, '\n",
        "                             f'threshold_level - {th}, drop_prob - {dp}.')\n",
        "                        model = GRUFixedLen(vocab_size=max_words, \n",
        "                                             embedding_dim=embedding_dim, hidden_dim=hidden_dim, \n",
        "                                             drop_prob=dp, use_last=False)\n",
        "                        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "                        model = model.to(device)\n",
        "                        model.train()\n",
        "                        th = th\n",
        "\n",
        "                        train_loss_history = []\n",
        "                        test_loss_history = []\n",
        "\n",
        "\n",
        "                        for epoch in range(epochs):  \n",
        "                            running_items, running_right = 0.0, 0.0\n",
        "                            for i, data in enumerate(train_loader, 0):\n",
        "                                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                                # обнуляем градиент\n",
        "                                optimizer.zero_grad()\n",
        "                                outputs = model(inputs)\n",
        "\n",
        "                                loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "                                loss.backward()\n",
        "                                optimizer.step()\n",
        "\n",
        "                                # подсчет ошибки на обучении\n",
        "                                loss = loss.item()\n",
        "                                running_items += len(labels)\n",
        "                                # подсчет метрики на обучении\n",
        "                                pred_labels = torch.squeeze((outputs > th).int())\n",
        "                                running_right += (labels == pred_labels).sum()\n",
        "\n",
        "                            # выводим статистику о процессе обучения\n",
        "                            model.eval()\n",
        "\n",
        "                            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                                    f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                                    f'Loss: {loss:.3f}. ' \\\n",
        "                                    f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "                            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "                            train_loss_history.append(loss)\n",
        "\n",
        "                                # выводим статистику на тестовых данных\n",
        "                            test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "                            for j, data in enumerate(val_loader):\n",
        "                                test_labels = data[1].to(device)\n",
        "                                test_outputs = model(data[0].to(device))\n",
        "\n",
        "                                # подсчет ошибки на тесте\n",
        "                                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                                # подсчет метрики на тесте\n",
        "                                test_running_total += len(data[1])\n",
        "                                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                                test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "                            test_loss_history.append(test_loss.item())\n",
        "                            print(f'Test loss: {test_loss:.3f}.' \n",
        "                                  f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "                            model.train()\n",
        "\n",
        "                        print('Training is finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aa763d8",
      "metadata": {
        "papermill": {
          "duration": 0.183058,
          "end_time": "2022-07-18T23:25:10.451252",
          "exception": false,
          "start_time": "2022-07-18T23:25:10.268194",
          "status": "completed"
        },
        "tags": [],
        "id": "6aa763d8"
      },
      "source": [
        "Видим, что данная модель на пяти эпохах показывает в целом сопоставимые результаты, на десяти эпохах показатели несколько хуже, чем у LSTM, но разница все равно довольно незначительная."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34b5acd",
      "metadata": {
        "papermill": {
          "duration": 0.183713,
          "end_time": "2022-07-18T23:25:10.815708",
          "exception": false,
          "start_time": "2022-07-18T23:25:10.631995",
          "status": "completed"
        },
        "tags": [],
        "id": "c34b5acd"
      },
      "source": [
        "Обучаем итоговую модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419eea2e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T23:25:11.185081Z",
          "iopub.status.busy": "2022-07-18T23:25:11.184688Z",
          "iopub.status.idle": "2022-07-18T23:25:11.196784Z",
          "shell.execute_reply": "2022-07-18T23:25:11.195578Z"
        },
        "papermill": {
          "duration": 0.199101,
          "end_time": "2022-07-18T23:25:11.199314",
          "exception": false,
          "start_time": "2022-07-18T23:25:11.000213",
          "status": "completed"
        },
        "tags": [],
        "id": "419eea2e"
      },
      "outputs": [],
      "source": [
        "model = LSTMFixedLen(vocab_size=max_words, \n",
        "                 embedding_dim=256, hidden_dim=96, \n",
        "                 drop_prob=0.1, use_last=False)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b219eaee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T23:25:11.570960Z",
          "iopub.status.busy": "2022-07-18T23:25:11.570611Z",
          "iopub.status.idle": "2022-07-18T23:25:11.576098Z",
          "shell.execute_reply": "2022-07-18T23:25:11.575152Z"
        },
        "papermill": {
          "duration": 0.190771,
          "end_time": "2022-07-18T23:25:11.578910",
          "exception": false,
          "start_time": "2022-07-18T23:25:11.388139",
          "status": "completed"
        },
        "tags": [],
        "id": "b219eaee",
        "outputId": "be81898c-d27b-434c-e5d7-6bafd76bd2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMFixedLen(\n",
            "  (embeddings): Embedding(1500, 256, padding_idx=0)\n",
            "  (lstm): LSTM(256, 96, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (linear): Linear(in_features=96, out_features=1, bias=True)\n",
            ")\n",
            "Parameters: 594529\n"
          ]
        }
      ],
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab17872b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-18T23:25:11.957432Z",
          "iopub.status.busy": "2022-07-18T23:25:11.957047Z",
          "iopub.status.idle": "2022-07-18T23:25:21.852981Z",
          "shell.execute_reply": "2022-07-18T23:25:21.851607Z"
        },
        "papermill": {
          "duration": 10.091076,
          "end_time": "2022-07-18T23:25:21.856449",
          "exception": false,
          "start_time": "2022-07-18T23:25:11.765373",
          "status": "completed"
        },
        "tags": [],
        "id": "ab17872b",
        "outputId": "fcf1bebe-49df-4449-a7f9-e40aa61ab4b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [44/44]. Loss: 0.140. Acc: 0.931. Test loss: 0.047.Test acc: 0.937\n",
            "Epoch [2/5]. Step [44/44]. Loss: 0.155. Acc: 0.944. Test loss: 0.046.Test acc: 0.946\n",
            "Epoch [3/5]. Step [44/44]. Loss: 0.103. Acc: 0.955. Test loss: 0.013.Test acc: 0.952\n",
            "Epoch [4/5]. Step [44/44]. Loss: 0.129. Acc: 0.963. Test loss: 0.498.Test acc: 0.952\n",
            "Epoch [5/5]. Step [44/44]. Loss: 0.097. Acc: 0.968. Test loss: 0.500.Test acc: 0.951\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "\n",
        "    # выводим статистику о процессе обучения\n",
        "    model.eval()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "            f'Loss: {loss:.3f}. ' \\\n",
        "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "        # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1].to(device)\n",
        "        test_outputs = model(data[0].to(device))\n",
        "\n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}.' \n",
        "          f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "print('Training is finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51b1891",
      "metadata": {
        "papermill": {
          "duration": 0.18861,
          "end_time": "2022-07-18T23:25:22.233680",
          "exception": false,
          "start_time": "2022-07-18T23:25:22.045070",
          "status": "completed"
        },
        "tags": [],
        "id": "a51b1891"
      },
      "source": [
        "В целом результаты обучения модели получилось довольно схожими с теми, что были получены при построении сети с применением одномерных сверток. Самыми эффективными гиперпараметрами для улучшения качества модели оказались скорость обучения (ее уменьшение) и размерность слоев: эмбеддинга и скрытого (их увеличение)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2693.985169,
      "end_time": "2022-07-18T23:25:25.270169",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-07-18T22:40:31.285000",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}